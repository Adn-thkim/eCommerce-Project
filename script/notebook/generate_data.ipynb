{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import uuid\n",
    "import math\n",
    "from itertools import combinations\n",
    "import random\n",
    "from faker import Faker\n",
    "import copy\n",
    "import ast\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import koreanize_matplotlib\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(action=\"ignore\")\n",
    "pd.set_option(\"display.max_rows\", 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed 고정\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "faker = Faker('ko_KR')\n",
    "Faker.seed(42)\n",
    "\n",
    "namespace = uuid.NAMESPACE_DNS\n",
    "\n",
    "# 사용자 수\n",
    "num_users = random.randint(100_000, 120_000)\n",
    "\n",
    "# ------------------------\n",
    "# 1) user_id\n",
    "# ------------------------\n",
    "user_id = np.arange(1, num_users + 1)\n",
    "\n",
    "# ------------------------\n",
    "# 2) gender (남/여 65:35)\n",
    "# ------------------------\n",
    "gender = np.random.choice(['M', 'F'], size=num_users, p=[0.65, 0.35])\n",
    "\n",
    "# ------------------------\n",
    "# 3) age (평균 25세, 15-45세 제한)\n",
    "# ------------------------\n",
    "main_part = int(num_users * 0.8)\n",
    "tail_part = num_users - main_part\n",
    "\n",
    "age_main = np.random.normal(loc=25, scale=3, size=main_part)  # 주요분포: 평균 25, 표준편차 3\n",
    "age_tail = np.random.normal(loc=30, scale=5, size=tail_part)  # 꼬리분포: 평균 30, 표준편차 5\n",
    "\n",
    "ages = np.concatenate([age_main, age_tail]) # 결합\n",
    "np.random.shuffle(ages)\n",
    "\n",
    "ages = np.clip(ages, 15, 45).round()  # 최종 범위: 15~45로 clip 후 정수화\n",
    "\n",
    "# ------------------------\n",
    "# 4) signup_date (20.01.01 - 24.12.31)\n",
    "# ------------------------\n",
    "# 연도별 확률 구간 정의\n",
    "signup_years = [2020, 2021, 2022, 2023, 2024]\n",
    "year_prob_ranges = {\n",
    "    2020: (0.01, 0.04),\n",
    "    2021: (0.03, 0.06),\n",
    "    2022: (0.15, 0.25),\n",
    "    2023: (0.35, 0.45),\n",
    "}\n",
    "\n",
    "# 구간 내에서 랜덤으로 확률 선택\n",
    "year_probs = [np.random.uniform(low, high) for (low, high) in year_prob_ranges.values()]\n",
    "year_probs.append(1 - np.sum(year_probs))\n",
    "\n",
    "# 가입 연도 생성\n",
    "signup_year = np.random.choice(signup_years, size=num_users, p=year_probs)\n",
    "\n",
    "# 월별 확률 설정 (합계 1로 정규화)\n",
    "month_probs = np.array([0.04, 0.04, 0.06, 0.07, 0.08, 0.12,\n",
    "                        0.15, 0.15, 0.11, 0.08, 0.06, 0.04])\n",
    "\n",
    "# 가입 월 생성 (1~12월 중 분포 기반 무작위 선택)\n",
    "signup_month = np.random.choice(range(1, 13), size=num_users, p=month_probs)\n",
    "\n",
    "# 가입 연도는 이전 로직에서 생성된 signup_year 활용\n",
    "signup_date = []\n",
    "for y, m in zip(signup_year, signup_month):\n",
    "    start_date = datetime(y, m, 1, 0, 0, 0)\n",
    "    if m == 12:\n",
    "        end_date = datetime(y, m, 31, 23, 59, 59)\n",
    "    else:\n",
    "        end_date = datetime(y, m + 1, 1, 0, 0, 0) - timedelta(seconds=1)\n",
    "    dt = faker.date_time_between(start_date=start_date, end_date=end_date)\n",
    "    signup_date.append(dt.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "# ------------------------\n",
    "# 5) birth (2025년 1월 1일 기준 만 나이, age로 산출)\n",
    "# ------------------------\n",
    "birth = []\n",
    "current_date = datetime(2025, 1, 1)\n",
    "birth_offsets = [timedelta(days=int(age*365 + np.random.randint(0, 364))) for age in ages]\n",
    "birth = [(current_date - offset).strftime('%Y-%m-%d') for offset in birth_offsets]\n",
    "\n",
    "# ------------------------\n",
    "# 5) 주소 (행정구역별 성별 인구통계 기반 랜덤 생성)\n",
    "# ------------------------\n",
    "region_df = pd.read_csv('./data/행정구역별_성별_인구통계_2025.csv')\n",
    "\n",
    "region_pop = region_df.groupby(['시도', '지역구'])['인구수'].sum().reset_index()\n",
    "region_pop['address'] = region_pop['시도'] + ' ' + region_pop['지역구']\n",
    "\n",
    "# 확률 계산\n",
    "region_pop['prob'] = region_pop['인구수'] / region_pop['인구수'].sum()\n",
    "regions = region_pop['address'].tolist()\n",
    "probs = region_pop['prob'].tolist()\n",
    "address = np.random.choice(regions, size=num_users, p=probs)\n",
    "\n",
    "# ------------------------\n",
    "# 6) 이름, 이메일 주소, 유입 경로\n",
    "# ------------------------\n",
    "first_names = [faker.first_name() for _ in range(num_users)]\n",
    "last_names = [faker.last_name() for _ in range(num_users)]\n",
    "emails = [f\"{str(uuid.uuid5(namespace, str(uid)))[:10]}@example.com\" for uid in user_id]\n",
    "\n",
    "# traffic_source = np.random.choice(traffic_sources, size=num_users)\n",
    "\n",
    "# 유입경로 종류\n",
    "traffic_sources = [\n",
    "    \"direct\", \"organic_search\", \"paid_search\",\n",
    "    \"facebook\", \"instagram\", \"kakao\",\n",
    "    \"naver\", \"email\", \"referral\"\n",
    "]\n",
    "\n",
    "# 연도별 유입경로 확률 분포 (2020년 ~ 2024년)\n",
    "yearly_source_probs = {\n",
    "    2020: [0.35, 0.40, 0.05, 0.03, 0.04, 0.02, 0.06, 0.01, 0.04],\n",
    "    2021: [0.40, 0.35, 0.05, 0.02, 0.05, 0.03, 0.05, 0.01, 0.04],\n",
    "    2022: [0.43, 0.32, 0.04, 0.02, 0.06, 0.03, 0.04, 0.01, 0.05],\n",
    "    2023: [0.45, 0.30, 0.03, 0.02, 0.07, 0.03, 0.04, 0.01, 0.05],\n",
    "    2024: [0.46, 0.28, 0.02, 0.02, 0.07, 0.03, 0.04, 0.01, 0.07]\n",
    "}\n",
    "\n",
    "# 가입 연도별 확률에 따라 traffic_source 할당\n",
    "traffic_source = [\n",
    "    np.random.choice(traffic_sources, p=yearly_source_probs[int(year)])\n",
    "    for year in signup_year\n",
    "]\n",
    "\n",
    "# ------------------------\n",
    "# 7) DataFrame 생성\n",
    "# ------------------------\n",
    "users_df = pd.DataFrame({\n",
    "    \"id\": user_id,\n",
    "    \"created_at\": signup_date,\n",
    "    \"first_name\": first_names,\n",
    "    \"last_name\": last_names,\n",
    "    \"email\": emails,\n",
    "    \"age\": ages,\n",
    "    \"birth\": birth,\n",
    "    \"gender\": gender,\n",
    "    \"address\": address,\n",
    "    \"traffic_source\": traffic_source\n",
    "})\n",
    "\n",
    "# 속성 타입 변환\n",
    "users_df[\"age\"] = users_df[\"age\"].astype(int)\n",
    "users_df[\"birth\"] = pd.to_datetime(users_df[\"birth\"])\n",
    "users_df[\"created_at\"] = pd.to_datetime(users_df[\"created_at\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV로 저장\n",
    "users_df.to_csv('./data/users.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서브카테고리별 비중 계산\n",
    "def build_subcats_weights(category_dict, subcat_weights):\n",
    "    \"\"\"\n",
    "    category_dict : dict\n",
    "        - {\"대분류\": [\"중분류1\", \"중분류2\", ...]}\n",
    "    subcat_weights : dict\n",
    "        - {\"대분류\": {\"중분류명\": 비율, ...}} : 지정한 중분류는 비율 반영, 나머지는 균등 분배\n",
    "\n",
    "    return : dict\n",
    "        - {\"대분류\": [중분류별 확률 배열]}\n",
    "    \"\"\"\n",
    "    full_weights = {}\n",
    "\n",
    "    for category, subcats in category_dict.items():\n",
    "        if category in subcat_weights:\n",
    "            weights_dict = subcat_weights[category]\n",
    "            weights = []\n",
    "            total_assigned = sum(weights_dict.values())\n",
    "            remaining_weight = 1.0 - total_assigned\n",
    "\n",
    "            other_subcats = [s for s in subcats if s not in weights_dict]\n",
    "            other_weight = remaining_weight / len(other_subcats) if other_subcats else 0\n",
    "\n",
    "            for s in subcats:\n",
    "                if s in weights_dict:\n",
    "                    weights.append(weights_dict[s])\n",
    "                else:\n",
    "                    weights.append(other_weight)\n",
    "        else:\n",
    "            # 모든 서브카테고리에 균등 분포\n",
    "            weights = [1 / len(subcats)] * len(subcats)\n",
    "\n",
    "        full_weights[category] = weights\n",
    "\n",
    "    return full_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성별 분류 함수\n",
    "def assign_department(category, sub_category):\n",
    "    if category in [\"원피스\", \"스커트\"]:\n",
    "        return \"여성\"\n",
    "    if category == \"속옷\":\n",
    "        if sub_category in [\"브라\", \"세트 속옷\", \"속바지\"]:\n",
    "            return \"여성\"\n",
    "        elif sub_category in [\"팬티\", \"이너웨어\"]:\n",
    "            p = np.array([0.2, 0.8])\n",
    "            return np.random.choice([\"남성\", \"여성\"], p=p)\n",
    "        else:\n",
    "            return \"여성\"\n",
    "    if category in [\"상의\", \"아우터\", \"바지\", \"신발\", \"가방\", \"액세서리\"]:\n",
    "        p = np.array([0.55, 0.35, 0.1])\n",
    "        return np.random.choice([\"남성\", \"여성\", \"공용\"], p=p)\n",
    "    return \"공용\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = Faker(\"ko_KR\")\n",
    "np.random.seed(42)\n",
    "\n",
    "# 카테고리 및 서브카테고리\n",
    "cat_subcat_dict = {\n",
    "    \"상의\": [\"반소매 티셔츠\", \"긴소매 티셔츠\", \"맨투맨\", \"셔츠/블라우스\", \"니트\", \"후드 티셔츠\"],\n",
    "    \"아우터\": [\"블루종\", \"레더 재킷\", \"코트\", \"패딩\", \"카디건\", \"기타 아우터\"],\n",
    "    \"바지\": [\"데님 팬츠\", \"슬랙스\", \"조거 팬츠\", \"숏 팬츠\", \"기타 바지\"],\n",
    "    \"원피스\": [\"미니 원피스\", \"셔츠 원피스\", \"미디 원피스\", \"니트 원피스\", \"맥시 원피스\"],\n",
    "    \"스커트\": [\"미니 스커트\", \"롱 스커트\", \"미디 스커트\"],\n",
    "    \"속옷\": [\"브라\", \"팬티\", \"이너웨어\", \"세트 속옷\", \"속바지\"],\n",
    "    \"신발\": [\"스니커즈\", \"부츠\", \"로퍼\", \"운동화\", \"샌들\", \"슬리퍼\", \"구두\", \"기타 신발\"],\n",
    "    \"가방\": [\"백팩\", \"크로스백\", \"숄더백\", \"기타 가방\"],\n",
    "    \"액세서리\": [\"모자\", \"벨트\", \"시계\", \"양말\", \"장갑\", \"안경/선글라스\", \"기타 악세사리\"]\n",
    "}\n",
    "\n",
    "# 서브카테고리 가중치 지정\n",
    "subcat_weights = {\n",
    "    \"상의\": {\"반소매 티셔츠\": 0.3, \"긴소매 티셔츠\": 0.25},\n",
    "    \"바지\": {\"데님 팬츠\": 0.35, \"슬랙스\": 0.3},\n",
    "    \"신발\": {\"스니커즈\": 0.3, \"운동화\": 0.25},\n",
    "    \"가방\": {\"백팩\": 0.4},\n",
    "    \"액세서리\": {\"모자\": 0.4}\n",
    "}\n",
    "\n",
    "# 가격 범위\n",
    "price_ranges = {\n",
    "    \"상의\": {\"반소매 티셔츠\": (15000, 39000), \"긴소매 티셔츠\": (20000, 49000), \"맨투맨\": (30000, 69000),\n",
    "           \"셔츠/블라우스\": (30000, 79000), \"니트\": (35000, 99000), \"후드 티셔츠\": (35000, 89000)},\n",
    "    \"아우터\": {\"블루종\": (50000, 129000), \"레더 재킷\": (99000, 199000), \"코트\": (99000, 250000),\n",
    "             \"패딩\": (109000, 300000), \"카디건\": (39000, 99000), \"기타 아우터\": (49000, 159000)},\n",
    "    \"바지\": {\"데님 팬츠\": (39000, 99000), \"슬랙스\": (39000, 89000), \"조거 팬츠\": (30000, 79000),\n",
    "           \"숏 팬츠\": (25000, 59000), \"기타 바지\": (29000, 79000)},\n",
    "    \"원피스\": {\"미니 원피스\": (40000, 99000), \"셔츠 원피스\": (49000, 109000), \"미디 원피스\": (49000, 119000),\n",
    "             \"니트 원피스\": (59000, 139000), \"맥시 원피스\": (59000, 149000)},\n",
    "    \"스커트\": {\"미니 스커트\": (30000, 69000), \"롱 스커트\": (39000, 89000), \"미디 스커트\": (39000, 79000)},\n",
    "    \"속옷\": {\"브라\": (15000, 59000), \"팬티\": (5000, 19000), \"이너웨어\": (10000, 35000),\n",
    "           \"세트 속옷\": (25000, 69000), \"속바지\": (10000, 29000)},\n",
    "    \"신발\": {\"스니커즈\": (45000, 139000), \"부츠\": (69000, 199000), \"로퍼\": (59000, 139000),\n",
    "           \"운동화\": (59000, 189000), \"샌들\": (29000, 79000), \"슬리퍼\": (19000, 49000),\n",
    "           \"구두\": (69000, 159000), \"기타 신발\": (30000, 129000)},\n",
    "    \"가방\": {\"백팩\": (45000, 129000), \"크로스백\": (35000, 99000), \"숄더백\": (39000, 109000),\n",
    "           \"기타 가방\": (30000, 99000)},\n",
    "    \"액세서리\": {\"벨트\": (19000, 59000), \"시계\": (69000, 259000),\n",
    "              \"양말\": (2000, 10000), \"장갑\": (5000, 29000), \"안경/선글라스\": (29000, 129000),\n",
    "              \"기타 악세사리\": (5000, 49000), \"모자\": (15000, 49000)}\n",
    "}\n",
    "\n",
    "# 카테고리별 브랜드\n",
    "category_brands = {\n",
    "  \"상의\": [\"Musinsa Standard\", \"Ouro\", \"Curetty\", \"RonRon\", \"J Vineyard\", \"Seez\", \"Kijiko\", \"Lowbi\", \"MuahMuah\", \"Lohnt\",\n",
    "          \"Holiday Outerwear\", \"ATAR\", \"Loiter Loiter\", \"Remain\", \"Pakke\", \"Arts de Base\", \"Thehere\", \"Moderate\", \"Nike\",\n",
    "          \"Adidas\", \"Stussy\", \"The North Face\", \"A Bathing Ape (BAPE)\", \"Supreme\", \"Carhartt WIP\", \"Vivienne Westwood\",\n",
    "          \"Arc’teryx\", \"New Balance\", \"Asics\", \"Oakley\", \"Palace\", \"MISCHIEF\", \"Human Made\", \"Converse\", \"Vans\", \"Puma\",\n",
    "          \"Fila\", \"Reebok\", \"Under Armour\", \"Discovery Expedition\", \"National Geographic Apparel\", \"Black Yak\", \"K2\",\n",
    "          \"Patagonia\", \"Columbia\", \"Stone Island\", \"Off-White\", \"thisisneverthat\", \"Andersson Bell\", \"87MM\", \"Covernat\",\n",
    "          \"LMC\", \"Mahagrid\", \"Kirsh\", \"5252 by O!Oi\", \"ADLV\", \"Nerdy\", \"MLB\", \"New Era\", \"SPAO\", \"Lucky Chouette\", \"CC Collect\",\n",
    "          \"Guess\", \"Levi’s\", \"Calvin Klein\", \"Tommy Hilfiger\", \"Ralph Lauren\", \"Lacoste\", \"Beyond Closet\", \"SJYP\", \"pushBUTTON\",\n",
    "          \"Minjukim\", \"YCH\", \"We11Done\", \"ADER Error\", \"Maje\", \"Iro\", \"Kuho\", \"ORR\", \"Egoist\", \"EENK\", \"Jill Stuart\",\n",
    "          \"Margarin Fingers\", \"Sandro\", \"DEW E DEW E\", \"Salomon\", \"Moncler\", \"Beanpole\", \"Kolon Sport\", \"Hazzys\", \"Daks\",\n",
    "          \"Henry Cotton’s\", \"Club Monaco\", \"Brooks Brothers\", \"Teenie Weenie\", \"Series\", \"Polo Jeans (Ralph Lauren)\",\n",
    "          \"Tommy Jeans\", \"McGregor\", \"Suitsupply\", \"Champion\", \"XEXYMIX\"],\n",
    "  \"아우터\": [\"Musinsa Standard\", \"Ouro\", \"Curetty\", \"RonRon\", \"J Vineyard\", \"Seez\", \"Kijiko\", \"Lowbi\", \"MuahMuah\", \"Lohnt\",\n",
    "           \"Holiday Outerwear\", \"ATAR\", \"Loiter Loiter\", \"Remain\", \"Pakke\", \"Arts de Base\", \"Thehere\", \"Moderate\", \"Nike\",\n",
    "           \"Adidas\", \"Stussy\", \"The North Face\", \"A Bathing Ape (BAPE)\", \"Supreme\", \"Carhartt WIP\", \"Vivienne Westwood\",\n",
    "           \"Arc’teryx\", \"New Balance\", \"Asics\", \"Oakley\", \"Palace\", \"MISCHIEF\", \"Human Made\", \"Converse\", \"Vans\", \"Puma\",\n",
    "           \"Fila\", \"Reebok\", \"Under Armour\", \"Discovery Expedition\", \"National Geographic Apparel\", \"Black Yak\", \"K2\",\n",
    "           \"Patagonia\", \"Columbia\", \"Stone Island\", \"Off-White\", \"thisisneverthat\", \"Andersson Bell\", \"87MM\", \"Covernat\",\n",
    "           \"LMC\", \"Mahagrid\", \"Kirsh\", \"5252 by O!Oi\", \"ADLV\", \"Nerdy\", \"MLB\", \"New Era\", \"SPAO\", \"Lucky Chouette\", \"CC Collect\",\n",
    "           \"Guess\", \"Levi’s\", \"Calvin Klein\", \"Tommy Hilfiger\", \"Ralph Lauren\", \"Lacoste\", \"Beyond Closet\", \"SJYP\", \"pushBUTTON\",\n",
    "           \"Minjukim\", \"YCH\", \"We11Done\", \"ADER Error\", \"Maje\", \"Iro\", \"Kuho\", \"ORR\", \"Egoist\", \"EENK\", \"Jill Stuart\",\n",
    "           \"Margarin Fingers\", \"Sandro\", \"DEW E DEW E\", \"Salomon\", \"Moncler\", \"Beanpole\", \"Kolon Sport\", \"Hazzys\", \"Daks\",\n",
    "           \"Henry Cotton’s\", \"Club Monaco\", \"Brooks Brothers\", \"Teenie Weenie\", \"Series\", \"Polo Jeans (Ralph Lauren)\",\n",
    "           \"Tommy Jeans\", \"McGregor\", \"Suitsupply\", \"Champion\", \"XEXYMIX\"],\n",
    "  \"바지\": [\"Musinsa Standard\", \"Ouro\", \"Curetty\", \"RonRon\", \"J Vineyard\", \"Seez\", \"Kijiko\", \"Lowbi\", \"MuahMuah\", \"Holiday Outerwear\",\n",
    "          \"Loiter Loiter\", \"Remain\", \"Pakke\", \"Arts de Base\", \"Thehere\", \"Moderate\", \"Nike\", \"Adidas\", \"Stussy\", \"The North Face\",\n",
    "          \"A Bathing Ape (BAPE)\", \"Supreme\", \"Carhartt WIP\", \"Vivienne Westwood\", \"Arc’teryx\", \"New Balance\", \"Asics\", \"Oakley\",\n",
    "          \"Palace\", \"MISCHIEF\", \"Human Made\", \"Converse\", \"Vans\", \"Puma\", \"Fila\", \"Reebok\", \"Under Armour\", \"Discovery Expedition\",\n",
    "          \"National Geographic Apparel\", \"Black Yak\", \"K2\", \"Patagonia\", \"Columbia\", \"Stone Island\", \"Off-White\", \"thisisneverthat\",\n",
    "          \"Andersson Bell\", \"87MM\", \"Covernat\", \"LMC\", \"Mahagrid\", \"Kirsh\", \"5252 by O!Oi\", \"ADLV\", \"Nerdy\", \"MLB\", \"SPAO\",\n",
    "          \"Lucky Chouette\", \"CC Collect\", \"Guess\", \"Levi’s\", \"Calvin Klein\", \"Tommy Hilfiger\", \"Ralph Lauren\", \"Lacoste\",\n",
    "          \"Beyond Closet\", \"SJYP\", \"pushBUTTON\", \"Minjukim\", \"YCH\", \"We11Done\", \"ADER Error\", \"Maje\", \"Iro\", \"Kuho\", \"ORR\", \"Egoist\",\n",
    "          \"EENK\", \"Jill Stuart\", \"Margarin Fingers\", \"Sandro\", \"DEW E DEW E\", \"Salomon\", \"Moncler\", \"Beanpole\", \"Kolon Sport\", \"Hazzys\",\n",
    "          \"Daks\", \"Henry Cotton’s\", \"Club Monaco\", \"Brooks Brothers\", \"Teenie Weenie\", \"Series\", \"Polo Jeans (Ralph Lauren)\",\n",
    "          \"Tommy Jeans\", \"McGregor\", \"Suitsupply\", \"Champion\", \"XEXYMIX\"],\n",
    "  \"가방\": [\"Musinsa Standard\", \"Ouro\", \"Curetty\", \"RonRon\", \"J Vineyard\", \"Lohnt\", \"Arts de Base\", \"Thehere\", \"Nike\", \"Adidas\", \"Stussy\",\n",
    "          \"The North Face\", \"A Bathing Ape (BAPE)\", \"Supreme\", \"Carhartt WIP\", \"Vivienne Westwood\", \"Arc’teryx\", \"New Balance\", \"Asics\",\n",
    "          \"Oakley\",\"Converse\", \"Dr. Martens\", \"Puma\", \"Fila\", \"Reebok\", \"Discovery Expedition\", \"National Geographic Apparel\", \"Black Yak\",\n",
    "          \"K2\", \"Patagonia\",\"Columbia\", \"Off-White\", \"Kirsh\", \"MLB\", \"Lucky Chouette\", \"Guess\", \"Calvin Klein\", \"Tommy Hilfiger\",\n",
    "          \"Ralph Lauren\", \"Lacoste\", \"Marhen J\", \"OSOI\", \"Maje\", \"ORR\", \"EENK\", \"Jill Stuart\", \"Sandro\", \"Salomon\", \"Beanpole\", \"Kolon Sport\",\n",
    "          \"Hazzys\", \"Daks\", \"Henry Cotton’s\"],\n",
    "  \"액세서리\": [\"Musinsa Standard\", \"Curetty\", \"RonRon\", \"J Vineyard\", \"Seez\", \"MuahMuah\", \"Holiday Outerwear\", \"ATAR\", \"Loiter Loiter\", \"Pakke\",\n",
    "             \"Arts de Base\", \"Thehere\", \"Nike\", \"Adidas\", \"Stussy\", \"The North Face\", \"A Bathing Ape (BAPE)\", \"Supreme\", \"Carhartt WIP\",\n",
    "             \"Vivienne Westwood\", \"Arc’teryx\", \"New Balance\", \"Asics\", \"Oakley\", \"Palace\", \"MISCHIEF\", \"Human Made\", \"Converse\", \"Vans\",\n",
    "             \"Dr. Martens\", \"Puma\", \"Fila\", \"Reebok\", \"Under Armour\", \"Discovery Expedition\", \"National Geographic Apparel\", \"Black Yak\",\n",
    "             \"K2\", \"Patagonia\", \"Columbia\", \"Stone Island\", \"Off-White\", \"thisisneverthat\", \"Andersson Bell\", \"87MM\", \"Covernat\", \"LMC\",\n",
    "             \"Mahagrid\", \"Kirsh\", \"5252 by O!Oi\", \"ADLV\", \"Nerdy\", \"MLB\", \"New Era\", \"SPAO\", \"Lucky Chouette\", \"Guess\", \"Levi’s\", \"Calvin Klein\",\n",
    "             \"Tommy Hilfiger\", \"Ralph Lauren\", \"Lacoste\", \"Beyond Closet\", \"SJYP\", \"pushBUTTON\", \"We11Done\", \"ADER Error\", \"Marhen J\", \"OSOI\",\n",
    "             \"Maje\", \"Iro\", \"EENK\", \"Jill Stuart\", \"Margarin Fingers\", \"Sandro\", \"DEW E DEW E\", \"Salomon\", \"Moncler\", \"Beanpole\", \"Kolon Sport\",\n",
    "             \"Hazzys\", \"Daks\", \"Henry Cotton’s\", \"Club Monaco\", \"Brooks Brothers\", \"Teenie Weenie\", \"Series\", \"Polo Jeans (Ralph Lauren)\",\n",
    "             \"Tommy Jeans\", \"McGregor\", \"Suitsupply\", \"Champion\", \"XEXYMIX\"],\n",
    "  \"속옷\": [\"Musinsa Standard\", \"SPAO\", \"Calvin Klein\", \"XEXYMIX\"],\n",
    "  \"신발\": [\"Musinsa Standard\", \"RonRon\", \"Lohnt\", \"Nike\", \"Adidas\", \"Stussy\", \"The North Face\", \"A Bathing Ape (BAPE)\", \"Supreme\", \"Carhartt WIP\",\n",
    "          \"Vivienne Westwood\", \"Arc’teryx\", \"New Balance\", \"Asics\", \"Oakley\", \"Palace\", \"Human Made\", \"Converse\", \"Vans\", \"Dr. Martens\", \"Puma\",\n",
    "          \"Fila\", \"Reebok\", \"Under Armour\", \"Discovery Expedition\", \"National Geographic Apparel\", \"Black Yak\", \"K2\", \"Patagonia\", \"Columbia\",\n",
    "          \"Off-White\", \"thisisneverthat\", \"Kirsh\", \"Nerdy\", \"MLB\", \"Lucky Chouette\", \"Guess\", \"Levi’s\", \"Calvin Klein\", \"Tommy Hilfiger\",\n",
    "          \"Ralph Lauren\", \"Lacoste\", \"We11Done\", \"ADER Error\", \"OSOI\", \"Salomon\", \"Moncler\", \"Beanpole\", \"Kolon Sport\", \"Hazzys\", \"Daks\",\n",
    "          \"Henry Cotton’s\", \"Brooks Brothers\", \"Series\", \"Polo Jeans (Ralph Lauren)\", \"Tommy Jeans\", \"McGregor\", \"Champion\"],\n",
    "  \"원피스\": [\"Ouro\", \"Curetty\", \"RonRon\", \"J Vineyard\", \"Kijiko\", \"MuahMuah\", \"Remain\", \"Pakke\", \"Arts de Base\", \"Thehere\", \"Moderate\", \"Nike\",\n",
    "           \"Adidas\", \"Stussy\", \"MISCHIEF\", \"Converse\", \"Andersson Bell\", \"Kirsh\", \"5252 by O!Oi\", \"Lucky Chouette\", \"CC Collect\", \"SJYP\", \"pushBUTTON\",\n",
    "           \"Minjukim\", \"YCH\", \"Maje\", \"Iro\", \"Kuho\", \"ORR\", \"Egoist\", \"EENK\", \"Jill Stuart\", \"Margarin Fingers\", \"Sandro\", \"DEW E DEW E\", \"Beanpole\",\n",
    "           \"Club Monaco\", \"Teenie Weenie\"],\n",
    "  \"스커트\": [\"Ouro\", \"Curetty\", \"RonRon\", \"J Vineyard\", \"Kijiko\", \"MuahMuah\", \"Remain\", \"Pakke\", \"Arts de Base\", \"Thehere\", \"Moderate\", \"Nike\",\n",
    "           \"Adidas\", \"Stussy\", \"MISCHIEF\", \"Converse\", \"Andersson Bell\", \"Kirsh\", \"5252 by O!Oi\", \"Lucky Chouette\", \"CC Collect\", \"SJYP\",\n",
    "           \"pushBUTTON\", \"Minjukim\", \"YCH\", \"Maje\", \"Iro\", \"Kuho\", \"ORR\", \"Egoist\", \"EENK\", \"Jill Stuart\", \"Margarin Fingers\", \"Sandro\",\n",
    "           \"DEW E DEW E\", \"Beanpole\", \"Club Monaco\", \"Teenie Weenie\"]\n",
    "}\n",
    "\n",
    "\n",
    "# 원가 비율 \n",
    "cost_rate_ranges = {\n",
    "    \"상의\": (0.45, 0.55),\n",
    "    \"아우터\": (0.40, 0.50),\n",
    "    \"바지\": (0.45, 0.55),\n",
    "    \"원피스\": (0.40, 0.50),\n",
    "    \"스커트\": (0.45, 0.55),\n",
    "    \"속옷\": (0.50, 0.60),\n",
    "    \"신발\": (0.40, 0.50),\n",
    "    \"가방\": (0.40, 0.50),\n",
    "    \"액세서리\": (0.50, 0.60)\n",
    "}\n",
    "\n",
    "# 제품 수 및 비율\n",
    "category_ratio = {\n",
    "    \"상의\": 0.22, \"아우터\": 0.15, \"바지\": 0.12, \"원피스\": 0.08,\n",
    "    \"스커트\": 0.05, \"속옷\": 0.06, \"신발\": 0.13, \"가방\": 0.10, \"액세서리\": 0.09\n",
    "}\n",
    "\n",
    "# 제품 생성\n",
    "total_products = 30000\n",
    "\n",
    "full_weights = build_subcats_weights(cat_subcat_dict, subcat_weights)\n",
    "products = []\n",
    "product_names = []\n",
    "namespace = uuid.NAMESPACE_DNS\n",
    "\n",
    "for category, subcats in cat_subcat_dict.items():\n",
    "    cat_count = int(total_products * category_ratio[category])\n",
    "    weights = full_weights[category]\n",
    "    subcat_counts = np.random.multinomial(cat_count, weights)\n",
    "    brand_pool = category_brands[category]\n",
    "    cost_low, cost_high = cost_rate_ranges[category]\n",
    "    \n",
    "    for subcat, count in zip(subcats, subcat_counts):\n",
    "        for _ in range(count):\n",
    "            brand = np.random.choice(brand_pool)\n",
    "            department = assign_department(category, subcat)\n",
    "            color = fake.color_name()\n",
    "            num = np.random.randint(1, 1000)\n",
    "            name = f\"{brand} {subcat} {color} {num}\"\n",
    "            \n",
    "            # name 중복 예외 처리\n",
    "            if name in product_names:\n",
    "                num = np.random.randint(1001, 2000)\n",
    "                name = f\"{brand} {subcat} {color} {num}\"\n",
    "\n",
    "            product_names.append(name)\n",
    "\n",
    "            low, high = price_ranges[category][subcat]\n",
    "            retail_price = (np.random.randint(low, high + 1) // 100) * 100\n",
    "            cost_factor = np.random.uniform(cost_low, cost_high)\n",
    "            cost = int((retail_price * cost_factor) // 100) * 100  # 원가도 100원 단위로 반올림\n",
    "\n",
    "            product_id = str(uuid.uuid5(namespace, str(name)))[:8]\n",
    "\n",
    "            products.append({\n",
    "                \"id\": product_id,\n",
    "                \"category\": category,\n",
    "                \"sub_category\": subcat,\n",
    "                \"name\": name,\n",
    "                \"brand\": brand,\n",
    "                \"cost\": cost,\n",
    "                \"retail_price\": retail_price,\n",
    "                \"department\": department\n",
    "            })\n",
    "\n",
    "# DataFrame 생성\n",
    "products_df = pd.DataFrame(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df.to_csv(\"./data/products.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Promotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 할인율 상수\n",
    "ALWAYS_ON_DISCOUNT = 0.10\n",
    "SEASONAL_DISCOUNT = 0.20\n",
    "\n",
    "# 최소 주문 금액 \n",
    "ALWAYS_MINIMUM_SALE_PRICE = 0\n",
    "SEASONAL_MINIMUM_SALE_PRICE = 50000\n",
    "\n",
    "# 최대 할인 금액 \n",
    "ALWAYS_MAXIMUM_DISCOUNT_PRICE = 300000\n",
    "SEASONAL_MAXIMUM_DISCOUNT_PRICE = 300000\n",
    "\n",
    "# 프로모션 타입\n",
    "ALWAYS_PROMOTION = '상시'\n",
    "SEASONAL_PROMOTION = '정기'\n",
    "\n",
    "# 프로모션 리스트 생성 \n",
    "promotions_lst = []\n",
    "\n",
    "# 타임 세일 프로모션 생성 \n",
    "time_sale = (\"타임세일\", datetime(2022, 1, 1), datetime(2024, 12, 31), ALWAYS_ON_DISCOUNT, ALWAYS_MINIMUM_SALE_PRICE, ALWAYS_MAXIMUM_DISCOUNT_PRICE, ALWAYS_PROMOTION)\n",
    "promotions_lst.append(time_sale)\n",
    "\n",
    "\n",
    "# 22, 23, 24년 설날 날짜\n",
    "new_years_dates = {\n",
    "    2022: \"2022-02-01\",\n",
    "    2023: \"2023-01-22\",\n",
    "    2024: \"2024-02-10\"\n",
    "}\n",
    "\n",
    "# 설날 프로모션 생성 \n",
    "for year, date in new_years_dates.items():\n",
    "    date_datetime = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "    start, end = date_datetime + timedelta(days=2), date_datetime + timedelta(days=8)\n",
    "    promotions_lst.append((\"설날 프로모션\", start, end, SEASONAL_DISCOUNT, SEASONAL_MINIMUM_SALE_PRICE, SEASONAL_MAXIMUM_DISCOUNT_PRICE, SEASONAL_PROMOTION))\n",
    "\n",
    "# 22, 23, 24년 추석 날짜 \n",
    "chuseok_dates = {\n",
    "    2022: \"2022-09-10\",\n",
    "    2023: \"2023-09-29\",\n",
    "    2024: \"2024-09-17\"\n",
    "}\n",
    "\n",
    "# 추석 프로모션 생성 \n",
    "for year, date in chuseok_dates.items():\n",
    "    date_datetime = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "    start, end = date_datetime + timedelta(days=2), date_datetime + timedelta(days=8)\n",
    "    promotions_lst.append((\"추석 프로모션\", start, end, SEASONAL_DISCOUNT, SEASONAL_MINIMUM_SALE_PRICE, SEASONAL_MAXIMUM_DISCOUNT_PRICE, SEASONAL_PROMOTION))\n",
    "\n",
    "# 봄 블랙프라이데이 생성\n",
    "for year in [2022, 2023, 2024]:\n",
    "    first_day = datetime(year, 5, 1)\n",
    "    first_monday = first_day + timedelta(days=(7 - first_day.weekday()) % 7)\n",
    "    start = first_monday + timedelta(weeks=1)\n",
    "    end = start + timedelta(days=13)\n",
    "    promotions_lst.append((\"봄 블랙프라이데이\", start, end, SEASONAL_DISCOUNT, SEASONAL_MINIMUM_SALE_PRICE, SEASONAL_MAXIMUM_DISCOUNT_PRICE, SEASONAL_PROMOTION))\n",
    "\n",
    "# 가을 블랙프라이데이 생성\n",
    "for year in [2022, 2023, 2024]:\n",
    "    first_day = datetime(year, 11, 1)\n",
    "    first_monday = first_day + timedelta(days=(7 - first_day.weekday()) % 7)\n",
    "    start = first_monday + timedelta(weeks=2)\n",
    "    end = start + timedelta(days=13)\n",
    "    promotions_lst.append((\"가을 블랙프라이데이\", start, end, SEASONAL_DISCOUNT, SEASONAL_MINIMUM_SALE_PRICE, SEASONAL_MAXIMUM_DISCOUNT_PRICE, SEASONAL_PROMOTION))\n",
    "\n",
    "\n",
    "# 생일자 프로모션\n",
    "birth_sale = (\"생일자 프로모션\", datetime(2022, 1, 1), datetime(2024, 12, 31), SEASONAL_DISCOUNT, SEASONAL_MINIMUM_SALE_PRICE, SEASONAL_MAXIMUM_DISCOUNT_PRICE, ALWAYS_PROMOTION)\n",
    "promotions_lst.append(birth_sale)\n",
    "\n",
    "\n",
    "promotions = []\n",
    "for i, (name, start, end, discount_rate, minimum_sale_price, maximum_discount_price, promotion_type) in enumerate(promotions_lst, 1):\n",
    "    promotions.append({\n",
    "        \"id\": i,\n",
    "        \"name\": name,\n",
    "        \"promotion_type\": promotion_type,\n",
    "        \"start_date\": start.strftime(\"%Y-%m-%d\"),\n",
    "        \"end_date\": end.strftime(\"%Y-%m-%d\"),\n",
    "        \"discount_rate\": discount_rate,\n",
    "        \"minimum_sale_price\": minimum_sale_price,\n",
    "        \"maximum_discount_price\": maximum_discount_price\n",
    "    })\n",
    "    \n",
    "promotions_df = pd.DataFrame(promotions)\n",
    "\n",
    "# 컬럼 속성 변경\n",
    "promotions_df['start_date'] = pd.to_datetime(promotions_df['start_date'])\n",
    "promotions_df['end_date'] = pd.to_datetime(promotions_df['end_date'])\n",
    "\n",
    "# 할인 없음 데이터 생성\n",
    "no_promo = {\n",
    "    \"id\": -1,\n",
    "    \"name\": \"할인 없음\",\n",
    "    \"promotion_type\": \"-\",\n",
    "    \"start_date\": pd.NaT,          # 기간 없음 → NULL\n",
    "    \"end_date\": pd.NaT,            # 기간 없음 → NULL\n",
    "    \"discount_rate\": 0.0,\n",
    "    \"minimum_sale_price\": 0,\n",
    "    \"maximum_discount_price\": 0\n",
    "}\n",
    "\n",
    "promotions_df = pd.concat([promotions_df, pd.DataFrame([no_promo])], ignore_index=True)\n",
    "promotions_df = promotions_df.sort_values(by='id', ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "promotions.to_csv(\"./data/promotions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prob_from_range(range_dict):\n",
    "    \"\"\"\n",
    "    주어진 범위(range_dict)에 따라 각 항목의 확률값을 생성하고, 전체 합이 1이 되도록 정규화된 확률 분포를 반환합니다.\n",
    "\n",
    "    input:\n",
    "        range_dict (dict): 각 항목에 대한 확률 범위를 지정하는 딕셔너리 (예: {\"A\": (0.1, 0.3), \"B\": (0.2, 0.4)})\n",
    "\n",
    "    return:\n",
    "        dict: 정규화된 확률값을 가진 딕셔너리 (예: {\"A\": 0.4, \"B\": 0.6})\n",
    "    \"\"\"\n",
    "    raw_probs = [np.random.uniform(low, high) for low, high in range_dict.values()]\n",
    "    norm_probs = np.array(raw_probs) / np.sum(raw_probs)\n",
    "    return dict(zip(range_dict.keys(), norm_probs))\n",
    "\n",
    "\n",
    "def adjust_traffic_for_month(base_probs, month):\n",
    "    \"\"\"\n",
    "    특정 월(month)에 따라 트래픽 소스별 비율을 조정한 후, 정규화된 확률분포를 반환합니다.\n",
    "\n",
    "    input:\n",
    "        base_probs (dict): 월과 무관한 기본 트래픽 소스별 비율\n",
    "        month (int): 조정할 월 (1~12)\n",
    "\n",
    "    return:\n",
    "        dict: 월별 특성을 반영하여 조정된 트래픽 소스별 확률 분포\n",
    "    \"\"\"\n",
    "    adj_probs = base_probs.copy()\n",
    "\n",
    "    # 1~2월: 검색 트래픽 강화, 유료 검색 감소\n",
    "    if month in [1, 2]:\n",
    "        adj_probs[\"organic_search\"] *= 1.2\n",
    "        adj_probs[\"paid_search\"] *= 0.8\n",
    "    # 6~8월: 소셜 및 유료 검색 강화, 검색 감소\n",
    "    elif month in [6, 7, 8]:\n",
    "        for k in [\"facebook\", \"instagram\", \"kakao\", \"paid_search\"]:\n",
    "            adj_probs[k] *= 1.3\n",
    "        adj_probs[\"organic_search\"] *= 0.7\n",
    "    # 11~12월: 직접 유입 및 유료 검색 강화, 검색 감소\n",
    "    elif month in [11, 12]:\n",
    "        adj_probs[\"direct\"] *= 1.3\n",
    "        adj_probs[\"paid_search\"] *= 1.4\n",
    "        adj_probs[\"organic_search\"] *= 0.6\n",
    "\n",
    "    # 정규화\n",
    "    total = sum(adj_probs.values())\n",
    "    return {k: v / total for k, v in adj_probs.items()}\n",
    "\n",
    "\n",
    "def generate_address_by_visitor_stats(created_at, visitor_df):\n",
    "    \"\"\"\n",
    "    방문 시간(created_at)에 따라 월별 방문자 통계를 기반으로 한 행정구역별 주소(address)를 무작위로 생성합니다.\n",
    "\n",
    "    input:\n",
    "        created_at (datetime): 이벤트 발생 시각\n",
    "        visitor_df (pd.DataFrame): 연도, 월, 행정구역별 방문자 수 통계가 포함된 데이터프레임\n",
    "            - 필수 컬럼: 'year', 'month', 'address', 'touNum' (방문자 수)\n",
    "\n",
    "    return:\n",
    "        str: 선택된 행정구역명 (예: \"서울특별시 강남구\")\n",
    "    \"\"\"\n",
    "    evt_year = created_at.year\n",
    "    evt_month = created_at.month\n",
    "\n",
    "    # 해당 연/월 데이터 필터링\n",
    "    filtered = visitor_df[(visitor_df['year'] == evt_year) & (visitor_df['month'] == evt_month)]\n",
    "    if filtered.empty:\n",
    "        # 월별 데이터가 없을 경우 전체 방문자 수 기반으로 address 비율 계산\n",
    "        filtered = visitor_df.groupby(\"address\").agg({\"touNum\": \"sum\"}).reset_index()\n",
    "        total = filtered[\"touNum\"].sum()\n",
    "        filtered[\"touRatio\"] = filtered[\"touNum\"] / total\n",
    "\n",
    "    addresses = filtered['address'].tolist()\n",
    "    probs = filtered['touRatio'].values\n",
    "    probs = probs / probs.sum()  # 정규화된 확률\n",
    "\n",
    "    return np.random.choice(addresses, p=probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_time_gap(prev_event, curr_event):\n",
    "    \"\"\"\n",
    "    이전 이벤트(prev_event)와 현재 이벤트(curr_event) 사이의 시간 간격(초 단위)을 \n",
    "    사용자 행동 특성에 기반하여 무작위로 생성합니다.\n",
    "\n",
    "    의류 e-commerce 플랫폼 사용자 흐름을 기반으로 이벤트 쌍별 시간 간격 분포를 반영합니다.\n",
    "    예를 들어 상품 상세 페이지(view_product) 이후 장바구니(add_to_cart)까지의 시간은 평균 1.5분 이상 소요되며,\n",
    "    로그인 이후 특정 행동까지는 수 초 ~ 수십 초 내외로 발생합니다.\n",
    "\n",
    "    input:\n",
    "        prev_event (str): 직전 이벤트 타입 (예: \"view_product\")\n",
    "        curr_event (str): 현재 이벤트 타입 (예: \"add_to_cart\")\n",
    "\n",
    "    return:\n",
    "        float: prev_event와 curr_event 사이의 시간 간격 (단위: 초)\n",
    "    \"\"\"\n",
    "    if (prev_event, curr_event) == (\"add_to_cart\", \"cart\"):\n",
    "        return np.random.uniform(0, 3)\n",
    "    elif (prev_event, curr_event) == (\"cart\", \"remove_from_cart\"):\n",
    "        return np.random.exponential(scale=60)\n",
    "    elif (prev_event, curr_event) == (\"click_promotion\", \"login\"):\n",
    "        return np.random.exponential(scale=20)\n",
    "    elif (prev_event, curr_event) == (\"click_promotion\", \"signup\"):\n",
    "        return np.random.exponential(scale=45)\n",
    "    elif (prev_event, curr_event) == (\"click_promotion\", \"view_product\"):\n",
    "        return abs(np.random.normal(loc=30, scale=10))\n",
    "    elif (prev_event, curr_event) == (\"login\", \"add_to_cart\"):\n",
    "        return np.random.uniform(0, 3)\n",
    "    elif (prev_event, curr_event) == (\"login\", \"cart\"):\n",
    "        return np.random.uniform(0, 3)\n",
    "    elif (prev_event, curr_event) == (\"login\", \"checkout\"):\n",
    "        return np.random.uniform(0, 3)\n",
    "    elif (prev_event, curr_event) == (\"login\", \"click_promotion\"):\n",
    "        return np.random.exponential(scale=12)\n",
    "    elif (prev_event, curr_event) == (\"login\", \"page_view\"):\n",
    "        return abs(np.random.normal(loc=7, scale=3))\n",
    "    elif (prev_event, curr_event) == (\"login\", \"profile\"):\n",
    "        return np.random.uniform(0, 3)\n",
    "    elif (prev_event, curr_event) == (\"login\", \"search\"):\n",
    "        return np.random.exponential(scale=8)\n",
    "    elif (prev_event, curr_event) == (\"login\", \"view_product\"):\n",
    "        return abs(np.random.normal(loc=15, scale=5))\n",
    "    elif (prev_event, curr_event) == (\"page_view\", \"login\"):\n",
    "        return abs(np.random.normal(loc=4, scale=2))\n",
    "    elif (prev_event, curr_event) == (\"page_view\", \"signup\"):\n",
    "        return np.random.exponential(scale=40)\n",
    "    elif (prev_event, curr_event) == (\"remove_from_cart\", \"cart\"):\n",
    "        return np.random.uniform(0, 3)\n",
    "    elif (prev_event, curr_event) == (\"search\", \"login\"):\n",
    "        return np.random.exponential(scale=20)\n",
    "    elif (prev_event, curr_event) == (\"search\", \"view_product\"):\n",
    "        return np.random.exponential(scale=45)\n",
    "    elif (prev_event, curr_event) == (\"session_start\", \"click_promotion\"):\n",
    "        return np.random.uniform(0, 3)\n",
    "    elif (prev_event, curr_event) == (\"session_start\", \"page_view\"):\n",
    "        return np.random.uniform(0, 3)\n",
    "    elif (prev_event, curr_event) == (\"session_start\", \"view_product\"):\n",
    "        return np.random.uniform(0, 3)\n",
    "    elif (prev_event, curr_event) == (\"signup\", \"click_promotion\"):\n",
    "        return np.random.exponential(scale=30)\n",
    "    elif (prev_event, curr_event) == (\"signup\", \"page_view\"):\n",
    "        return abs(np.random.normal(loc=25, scale=10))\n",
    "    elif (prev_event, curr_event) == (\"signup\", \"search\"):\n",
    "        return abs(np.random.normal(loc=20, scale=5))\n",
    "    elif (prev_event, curr_event) == (\"signup\", \"view_product\"):\n",
    "        return abs(np.random.normal(loc=30, scale=10))\n",
    "    elif (prev_event, curr_event) == (\"view_product\", \"add_to_cart\"):\n",
    "        return np.random.exponential(scale=90)\n",
    "    elif (prev_event, curr_event) == (\"view_product\", \"checkout\"):\n",
    "        return np.random.exponential(scale=120)\n",
    "    elif (prev_event, curr_event) == (\"view_product\", \"login\"):\n",
    "        return np.random.exponential(scale=15)\n",
    "    elif (prev_event, curr_event) == (\"view_product\", \"signup\"):\n",
    "        return np.random.exponential(scale=60)\n",
    "    elif (prev_event, curr_event) == (\"checkout\", \"purchase\"):\n",
    "        return abs(np.random.normal(loc=120, scale=60))\n",
    "    elif prev_event == curr_event:\n",
    "        return np.random.exponential(scale=20)  # 동일 이벤트 반복\n",
    "    else:\n",
    "        return np.random.exponential(scale=6)  # scroll 가정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_search_event_count():\n",
    "    \"\"\"\n",
    "    국내 의류 e-commerce 사용자 특성 기반 세션당 검색 이벤트 수를 생성합니다.\n",
    "    \n",
    "    - 전체 세션 중 약 35%는 검색을 수행\n",
    "    - 검색한 세션 중 약 22%는 2회 이상 반복 검색\n",
    "    \n",
    "    return: int (search 이벤트 수)\n",
    "    \"\"\"\n",
    "    base_prob = random.random()\n",
    "\n",
    "    if base_prob < 0.35:\n",
    "        # 검색 수행 세션\n",
    "        repeat_prob = random.random()\n",
    "        if repeat_prob < 0.22:\n",
    "            return random.choice([2, 3])  # 반복 검색\n",
    "        else:\n",
    "            return 1  # 1회 검색\n",
    "    else:\n",
    "        return 0  # 검색 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_session_events(session_id, user_id, user_is_new, source, session_time, promotion_df, forced_event_type=None):\n",
    "    \"\"\"\n",
    "    하나의 사용자 세션에서 발생할 고객 행동 이벤트 시퀀스를 생성합니다.\n",
    "\n",
    "    사용자의 방문 유형(신규/기존), 트래픽 소스(direct, 검색, SNS 등), 탐색 및 구매 여부에 따라 \n",
    "    search, page_view, view_product, add_to_cart, remove_from_cart, purchase 등의 실제적인 행동 흐름을 구성합니다.\n",
    "    각 이벤트는 사용자의 특성 및 세션 길이에 기반하여 확률적으로 삽입됩니다.\n",
    "\n",
    "    input:\n",
    "        session_id (str): 세션의 고유 ID (사용자 구분 및 연관 관계 추적용)\n",
    "        user_id (int): 해당 세션의 사용자 ID\n",
    "        user_is_new (bool): True일 경우 신규 유저로 간주되어 signup 이벤트가 포함됩니다\n",
    "        source (str): 해당 세션의 트래픽 유입 경로 (예: 'direct', 'organic_search', 'kakao' 등)\n",
    "\n",
    "    return:\n",
    "        list[str]: 세션 내 사용자 행동 이벤트 시퀀스 리스트\n",
    "                   (예: ['page_view', 'view_product', 'add_to_cart', 'purchase', 'logout'])\n",
    "    \"\"\"\n",
    "    events = []\n",
    "\n",
    "    # 1. 초기 진입 이벤트 결정 (채널별 첫 이벤트 설정)\n",
    "    if source == 'direct':\n",
    "        # Direct 유입 시 첫 이벤트는 page_view (예: 홈페이지 방문)\n",
    "        events.append('page_view')\n",
    "    else:\n",
    "        # 검색 또는 SNS 유입 시 첫 이벤트를 랜덤 선택 (page_view, view_product, click_promotion 중 하나)\n",
    "        first_event_candidates = ['page_view', 'view_product', 'click_promotion']\n",
    "        events.append(random.choice(first_event_candidates))\n",
    "\n",
    "    # 2. 이후 이벤트 구성:\n",
    "    # 세션 길이를 임의로 결정하고 이벤트들을 랜덤하게 선택하되 구매/장바구니 관련 규칙 적용\n",
    "    # 세션 길이가 짧으면 탐색 위주 이벤트만 포함하도록 조정\n",
    "\n",
    "    year = session_time.year\n",
    "\n",
    "    regular_promotions = promotion_df[(promotion_df['promotion_type']=='정기') & (promotion_df['start_date'].dt.year ==year)]\n",
    "    regular_promotions = regular_promotions[(regular_promotions['start_date'] <= session_time) & (regular_promotions['end_date'] >= session_time)]\n",
    "    \n",
    "    user_birth_month = users_df.loc[users_df['id']==user_id, 'birth'].dt.month.values[0]\n",
    "\n",
    "    if (len(regular_promotions) > 0) or (session_time.month == user_birth_month):\n",
    "        probs = (\n",
    "\t\t    [0.03, 0.03, 0.04] +             # 3~5\n",
    "\t\t    [0.09, 0.1, 0.1, 0.09, 0.08] +   # 6~10\n",
    "\t\t    [0.07, 0.06, 0.05] +             # 11~13\n",
    "\t\t    [0.04, 0.03, 0.02] +             # 14~16\n",
    "\t\t    [0.01, 0.01]                     # 17~18\n",
    "\t\t)\n",
    "    else:\n",
    "        probs = [0.05]*3 + [0.08]*4 + [0.06]*3 + [0.03]*3 + [0.01]*3\n",
    "        \n",
    "    probs /= np.sum(probs)\n",
    "\n",
    "    session_length = np.random.choice(\n",
    "        list(range(3, 19)),\n",
    "        p=probs\n",
    "    )\n",
    "\n",
    "    # 구매 및 장바구니 관련 플래그 초기화\n",
    "    has_purchase = False\n",
    "    has_add_to_cart = False\n",
    "\n",
    "    # 구매 여부 결정: 세션 이벤트가 6개 이상인 경우에만 구매 시나리오 고려 (짧은 세션은 구매 없음)\n",
    "    if session_length > 5:\n",
    "        # 예: 30% 확률로 구매 이벤트를 포함하는 세션으로 지정\n",
    "        has_purchase = (random.random() < 0.3)\n",
    "    else:\n",
    "        has_purchase = False  # 5개 이하 이벤트 세션은 구매 없음\n",
    "\n",
    "    # 구매 시나리오가 아니면 장바구니 담기만 하는 경우를 소량 허용 (낮은 확률)\n",
    "    num_add_to_cart_events = 0\n",
    "    if has_purchase:\n",
    "        # 구매 세션인 경우: 최소 1개 이상의 add_to_cart 발생\n",
    "        num_add_to_cart_events = random.randint(1, 3)\n",
    "        has_add_to_cart = True  # 구매 세션이므로 add_to_cart 이벤트는 반드시 발생\n",
    "    else:\n",
    "        # 구매 없는 세션에서 가끔 장바구니 담기만 하는 시나리오 발생 (세션이 충분히 길 때 낮은 확률)\n",
    "        if session_length > 5 and random.random() < 0.2:\n",
    "            has_add_to_cart = True\n",
    "            num_add_to_cart_events = random.randint(1, 2)  # 구매 없이 담기만 하는 경우 1-2회\n",
    "\n",
    "    # 3. 메인 이벤트 흐름 작성\n",
    "\n",
    "    # 탐색 중심 이벤트 생성\n",
    "    for _ in range(session_length):\n",
    "        events.append(random.choice(['page_view', 'view_product', 'click_promotion']))\n",
    "\n",
    "    # first_event가 'view_product'인 경우, 10-30% 확률로 직후에 add_to_cart 삽입\n",
    "    if events[0] == 'view_product' and random.random() < 0.2:\n",
    "        events.insert(1, 'add_to_cart')\n",
    "        has_add_to_cart = True\n",
    "\n",
    "        if num_add_to_cart_events > 0:\n",
    "            num_add_to_cart_events -= 1\n",
    "\n",
    "    # 검색 이벤트 추가\n",
    "    num_search_events = generate_search_event_count()\n",
    "    if events[1] == 'add_to_cart':\n",
    "        search_indices = random.choices(range(2, len(events)+1), k=num_search_events)\n",
    "    else:\n",
    "        search_indices = random.choices(range(1, len(events)+1), k=num_search_events)\n",
    "    for index in search_indices:\n",
    "        events.insert(index, 'search')\n",
    "\n",
    "    # add_to_cart 삽입\n",
    "    if has_add_to_cart:\n",
    "        # 예외처리 : has_add_to_cart인데, 랜덤 생성 과정에서 view_product가 생성되지 않은 경우, view_product 추가\n",
    "        if 'view_product' not in events:\n",
    "            vp_valid_indices = [idx for idx, event in enumerate(events) if event in ['page_view', 'search', 'click_promotion']]\n",
    "            events.insert(random.choice(vp_valid_indices)+1, 'view_product')\n",
    "\n",
    "        added_cart = 0\n",
    "        view_product_indices = [index for index, event in enumerate(events) if event == 'view_product']\n",
    "\n",
    "        # 예외처리 : 이벤트의 시작 sequence가 view_product → add_to_cart 일 경우, view_product_indices에서 0번 인덱스 제거\n",
    "        if (events[0] == 'view_product') and (events[1] == 'add_to_cart'):\n",
    "            view_product_indices.remove(0)\n",
    "\n",
    "        num_add_to_cart_events = min(num_add_to_cart_events, len(view_product_indices))\n",
    "\n",
    "        while added_cart < num_add_to_cart_events:\n",
    "            # view_product 바로 뒤에 add_to_cart 삽입\n",
    "            view_product_index = random.choice(view_product_indices)\n",
    "            events.insert(view_product_index+1, 'add_to_cart')\n",
    "            view_product_indices.remove(view_product_index)\n",
    "            view_product_indices = [idx + 1 if idx > view_product_index else idx for idx in view_product_indices]\n",
    "\n",
    "            added_cart += 1\n",
    "\n",
    "        has_add_to_cart = 'add_to_cart' in events\n",
    "\n",
    "    # 4. purchase 삽입 (has_purchase True일 경우, add_to_cart 이후 랜덤한 위치)\n",
    "    if has_purchase and has_add_to_cart:\n",
    "        # add_to_cart 이후 위치에 삽입\n",
    "        cart_indices = [index for index, event in enumerate(events) if event == 'add_to_cart']\n",
    "        invalid_indices = []\n",
    "        for idx in cart_indices:\n",
    "            if len(invalid_indices) == 0:\n",
    "                invalid_indices.extend(list(range(0, idx+1)))  # purchase는 최초 add_to_cart보다 선행할 수 없음\n",
    "            else:\n",
    "                invalid_indices.extend(list(range(idx-1, idx+1)))  # page_view → view_product → add_to_cart 사이에 위치할 수 없음\n",
    "        \n",
    "        # purchase 이벤트가 위치할 수 없는 인덱스 중복 제거 및 정렬\n",
    "        invalid_indices = set(invalid_indices)\n",
    "        invalid_indices = sorted(list(invalid_indices))\n",
    "\n",
    "        pc_valid_indices = [idx for idx in range(0, len(events)) if idx not in invalid_indices]\n",
    "        purchase_index = random.choice(pc_valid_indices) if pc_valid_indices else len(events)\n",
    "\n",
    "        # 예외처리 : 구매 이벤트를 삽입할 위치에 view_product가 있는 경우, 구매 이벤트 위치 조정\n",
    "        # ex. page_view(or search or click_promotion) → view_product 일때, page_view와 view_product 사이에 purchase가 위치하는 것 방지\n",
    "        # print(f\"pc_valid_indices: {pc_valid_indices}, purchase_index: {purchase_index}, length of events: {len(events)}\")\n",
    "        while pc_valid_indices:\n",
    "            if events[purchase_index] == 'view_product':\n",
    "                pc_valid_indices.remove(purchase_index)\n",
    "                purchase_index = random.choice(pc_valid_indices) if pc_valid_indices else len(events)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        events.insert(purchase_index, 'purchase')\n",
    "        events.insert(purchase_index, 'checkout')\n",
    "\n",
    "        if events[purchase_index-1] != 'view_product':\n",
    "            events.insert(purchase_index, 'page_view')\n",
    "\n",
    "        # 취소 이벤트 삽입 (구매 이벤트 이후 2.5% 확률로 취소 이벤트 삽입)\n",
    "        cancel_prob = np.random.beta(a=1.2, b=60)\n",
    "        if np.random.rand() < cancel_prob:\n",
    "            purchase_index = events.index('purchase')\n",
    "            cart_indices = [index for index, event in enumerate(events) if (event == 'add_to_cart') & (index > purchase_index)]\n",
    "\n",
    "            invalid_indices = []\n",
    "            invalid_indices.extend(list(range(0, purchase_index+1))) # purchase 이전 인덱스 제외\n",
    "            for idx in cart_indices:\n",
    "                invalid_indices.extend(list(range(idx-1, idx+1)))  # page_view → view_product → add_to_cart 사이에 위치할 수 없음\n",
    "\n",
    "            # cancel_order 이벤트가 위치할 수 없는 인덱스 중복 제거 및 정렬\n",
    "            invalid_indices = set(invalid_indices)\n",
    "            invalid_indices = sorted(list(invalid_indices))\n",
    "\n",
    "            cancel_valid_indices = [idx for idx in range(0, len(events)+1) if idx not in invalid_indices]\n",
    "            \n",
    "            # 예외처리 : cancel_order 이벤트가 위치할 수 없는 인덱스가 없는 경우, page_view와 cancel_order를 마지막 위치에 추가\n",
    "            cancel_index = random.choice(cancel_valid_indices) if cancel_valid_indices else len(events)\n",
    "\n",
    "            events.insert(cancel_index, 'cancel_order')\n",
    "            events.insert(cancel_index, 'page_view')\n",
    "\n",
    "\n",
    "    # 5. remove_from_cart 이벤트 삽입 (확률적으로)\n",
    "\n",
    "    ## 약 15% 확률로 remove_from_cart 발생\n",
    "    is_remove_from_cart = (random.random() < 0.15)\n",
    "\n",
    "    # 구매 세션: 장바구니에 2회 이상 담았으면 일부 상품 제거 이벤트 발생 가능\n",
    "    case_1 = ('purchase' in events) and (events.count('add_to_cart') >= 2)\n",
    "\n",
    "    # 비구매 세션\n",
    "    case_2 = (has_add_to_cart) and ('purchase' not in events)\n",
    "\n",
    "    if (case_1 or case_2) and is_remove_from_cart:\n",
    "        cart_indices = [index for index, event in enumerate(events) if event == 'add_to_cart']\n",
    "\n",
    "        invalid_indices = []\n",
    "\n",
    "        # case_1 구매 세션: invalid_indices에 add_to_cart, purchase, cancel_order 위치 추가\n",
    "        if case_1:\n",
    "            purchase_index = events.index('purchase')\n",
    "            second_add_to_cart_index = cart_indices[1]  # 2번째 add_to_cart 이벤트 위치\n",
    "\n",
    "            # purchase가 최초 add_to_cart의 후행일때 add_to_cart → purchase → add_to_cart\n",
    "            # add_to_cart와 purchase 사이에 위치할 수 없음 (cart가 비어있을 때 purchase or remove_from_cart 발생 금지)\n",
    "            if purchase_index < second_add_to_cart_index:\n",
    "                invalid_indices.extend(list(range(0, second_add_to_cart_index+1)))\n",
    "\n",
    "                for idx in cart_indices[2:]:\n",
    "                    invalid_indices.extend(list(range(idx-1, idx+1)))  # page_view → view_product → add_to_cart 사이에 위치할 수 없음\n",
    "\n",
    "            # add_to_cart → add_to_cart → purchase\n",
    "            else:\n",
    "                for idx in cart_indices:\n",
    "                    if len(invalid_indices) == 0:\n",
    "                        invalid_indices.extend(list(range(0, idx+1)))  # remove_from_cart는 최초 add_to_cart보다 선행할 수 없음\n",
    "                    else:\n",
    "                        invalid_indices.extend(list(range(idx-1, idx+1)))  # page_view → view_product → add_to_cart 사이에 위치할 수 없음\n",
    "\n",
    "                invalid_indices.extend(list(range(purchase_index-1, purchase_index+1)))  # page_view(profile) → checkout → purchase 사이에 위치할 수 없음\n",
    "            \n",
    "            if 'cancel_order' in events:\n",
    "                cancel_index = events.index('cancel_order')\n",
    "                invalid_indices.append(cancel_index)  # page_view(profile) → cancel_order 사이에 위치할 수 없음\n",
    "\n",
    "        # case_2 비구매 세션: invalid_indices에 add_to_cart 이벤트 위치 추가\n",
    "        else:\n",
    "            for idx in cart_indices:\n",
    "                if len(invalid_indices) == 0:\n",
    "                    invalid_indices.extend(list(range(0, idx+1)))  # remove_from_cart는 add_to_cart보다 선행할 수 없음\n",
    "                else:\n",
    "                    invalid_indices.extend(list(range(idx-1, idx+1)))  # page_view → view_product → add_to_cart 사이에 위치할 수 없음\n",
    "\n",
    "        # purchase 이벤트가 위치할 수 없는 인덱스 중복 제거 및 정렬\n",
    "        invalid_indices = set(invalid_indices)\n",
    "        invalid_indices = sorted(list(invalid_indices))\n",
    "\n",
    "        remove_valid_indices = [idx for idx in range(0, len(events)+1) if idx not in invalid_indices]\n",
    "\n",
    "        # 예외처리 : remove_from_cart 이벤트가 위치할 수 없는 인덱스가 없는 경우, page_view와 remove_from_cart를 마지막 위치에 추가\n",
    "        remove_index = random.choice(remove_valid_indices) if remove_valid_indices else len(events)\n",
    "\n",
    "        events.insert(remove_index, 'remove_from_cart')\n",
    "        events.insert(remove_index, 'page_view')\n",
    "\n",
    "    # 6. 반품/리뷰 이벤트 삽입 (forced_event_type값이 있을 경우)\n",
    "    if forced_event_type:\n",
    "        # 반품 또는 리뷰 이벤트 삽입 위치 결정 (add_to_cart 바로 앞은 피함)\n",
    "        add_to_cart_indices = [idx for idx, evt in enumerate(events) if evt == 'add_to_cart']\n",
    "        purchase_index = events.index('purchase') if 'purchase' in events else None\n",
    "        disallowed = set()\n",
    "        for ac_idx in add_to_cart_indices:\n",
    "            disallowed.add(ac_idx)          # add_to_cart 위치 바로 앞은 금지\n",
    "            disallowed.add(ac_idx-1)        # add_to_cart 이전 인덱스도 금지\n",
    "        if purchase_index is not None:\n",
    "            disallowed.add(purchase_index)  # purchase 바로 앞 위치는 금지\n",
    "            disallowed.add(purchase_index-1)\n",
    "        # 가능한 삽입 위치 계산 (0 ~ len(events) 사이, disallowed 제외)\n",
    "        possible_positions = [pos for pos in range(0, len(events)+1) if pos not in disallowed]\n",
    "        insert_pos = random.choice(possible_positions) if possible_positions else len(events)\n",
    "        events.insert(insert_pos, forced_event_type)\n",
    "        events.insert(insert_pos, 'page_view')  # profile 페이지 방문 이벤트 추가 (반품/리뷰 이벤트 이후 방문)\n",
    "\n",
    "    # 7. 로그인 및 회원가입 이벤트 삽입\n",
    "    login_required_events = {'add_to_cart', 'remove_from_cart', 'purchase', 'logout', 'return', 'review'}\n",
    "    needs_login = any(event in login_required_events for event in events)\n",
    "    if needs_login:\n",
    "        # 로그인 필요한 이벤트 중 첫 번째의 인덱스 찾기\n",
    "        first_login_index = None\n",
    "        for idx, event in enumerate(events):\n",
    "            if event in login_required_events:\n",
    "                first_login_index = idx\n",
    "                break\n",
    "        if first_login_index is None:\n",
    "            first_login_index = len(events)\n",
    "        # 첫 로그인 필요 이벤트보다 앞선 범위 내에서 랜덤 위치 선정\n",
    "        insert_index = random.randint(1, first_login_index) if first_login_index > 0 else 0\n",
    "\n",
    "        # 신규 유저인 경우 회원가입 이벤트를 먼저 추가\n",
    "        if user_is_new:\n",
    "            events.insert(insert_index, 'signup')\n",
    "            insert_index += 1\n",
    "        # 로그인 이벤트 추가\n",
    "        events.insert(insert_index, 'login')\n",
    "    else:\n",
    "        # 로그인 필요 이벤트가 없지만 일부 세션은 로그인만 수행 (20% 확률, 신규면 회원가입 후 로그인)\n",
    "        if random.random() < 0.2:\n",
    "            insert_index = random.randint(1, len(events))\n",
    "            if user_is_new:\n",
    "                events.insert(insert_index, 'signup')\n",
    "                events.insert(insert_index + 1, 'login')\n",
    "            else:\n",
    "                events.insert(insert_index, 'login')\n",
    "                \n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# 재방문 간격(일) 분포 파라미터\n",
    "SESSION_GAP_CFG = {\n",
    "    # 충성: 지수분포(평균 5일), 꼬리 약간 허용\n",
    "    'loyal':   {'dist': 'exponential', 'mean': 5.0,   'clip': (1, 45)},\n",
    "\n",
    "    # 일반: \"초기 버스트(짧은 간격)\" + \"안정기(긴 간격)\" 혼합\n",
    "    #  - burst_prob 확률로 지수(평균 7일)에서 추출 → 초반 탐색 활발\n",
    "    #  - 그 외는 로그정규(평균≈25일, sigma=0.7) → 중장기 완만\n",
    "    'regular': {'dist': 'mixture_lognorm',\n",
    "                'burst_prob': 0.25, 'burst_mean': 7.0,\n",
    "                'mean': 40.0, 'sigma': 0.70,\n",
    "                'clip': (3, 120)},\n",
    "\n",
    "    # 휴면: 지수(평균 120일)로 더 느리게, 하한 14일\n",
    "    'dormant': {'dist': 'exponential', 'mean': 120.0, 'clip': (14, 600)},\n",
    "}\n",
    "\n",
    "def _sample_lognormal_days(mean, sigma, size=1, rng=rng):\n",
    "    \"\"\"\n",
    "    로그정규의 평균을 mean으로 맞추기 위한 mu 계산: E[X] = exp(mu + 0.5*sigma^2)\n",
    "    input:\n",
    "        mean (float): 목표 평균(일)\n",
    "        sigma (float): 로그정규 표준편차\n",
    "        size (int): 샘플 개수\n",
    "    return:\n",
    "        np.ndarray: 일(day) 단위 샘플\n",
    "    \"\"\"\n",
    "    mu = np.log(mean) - 0.5 * (sigma ** 2)\n",
    "    return rng.lognormal(mean=mu, sigma=sigma, size=size)\n",
    "\n",
    "def sample_session_gap_days(user_type: str, rng=rng) -> timedelta:\n",
    "    \"\"\"\n",
    "    등급별 재방문 간격을 '연속값'으로 샘플링하여 Timedelta로 반환.\n",
    "    - loyal: 지수(mean)\n",
    "    - regular: 혼합(버스트: 지수 / 일반: 로그정규)\n",
    "    - dormant: 지수(mean)\n",
    "\n",
    "    기존 clip을 그대로 적용하되, '반올림'은 하지 않음(시간 단위 비교를 위해 연속값 유지).\n",
    "    \"\"\"\n",
    "    cfg = SESSION_GAP_CFG[user_type]\n",
    "    lo, hi = cfg['clip']\n",
    "\n",
    "    if cfg['dist'] == 'exponential':\n",
    "        val = rng.exponential(scale=cfg['mean'], size=1)[0]\n",
    "    elif cfg['dist'] == 'lognormal':\n",
    "        val = _sample_lognormal_days(cfg['mean'], cfg['sigma'], size=1, rng=rng)[0]\n",
    "    elif cfg['dist'] == 'mixture_lognorm':\n",
    "        if rng.random() < cfg['burst_prob']:\n",
    "            val = rng.exponential(scale=cfg['burst_mean'], size=1)[0]\n",
    "        else:\n",
    "            val = _sample_lognormal_days(cfg['mean'], cfg['sigma'], size=1, rng=rng)[0]\n",
    "    else:\n",
    "        raise ValueError(f\"unknown dist for {user_type}\")\n",
    "\n",
    "    # 하한/상한 클리핑 (연속값 유지)\n",
    "    val = float(np.clip(val, lo, hi))\n",
    "    return timedelta(days=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# EWMA(지수가중 이동합) 설정값\n",
    "# ---------------------------------------\n",
    "EWM_HALFLIFE = {\n",
    "    \"sessions\": 45.0,   # 세션 활동의 반감기(일)\n",
    "    \"purchases\": 60.0   # 구매 활동의 반감기(일)\n",
    "}\n",
    "\n",
    "@dataclass\n",
    "class UserState:\n",
    "    \"\"\"\n",
    "    세션 생성 중 사용자 상태(등급, 최근활동지표, 이탈 여부)를 보관하는 경량 컨테이너.\n",
    "\n",
    "    속성:\n",
    "        user_id (int): 사용자 ID\n",
    "        tier (str): 현재 등급 ('loyal'|'regular'|'dormant')\n",
    "        churned (bool): 이탈 여부 플래그. True면 이후 세션 생성 중단\n",
    "        last_update (datetime): 최근활동(EWMA) 마지막 갱신 시각\n",
    "        ewm_sessions (float): 지수가중 세션 활동 점수\n",
    "        ewm_purchases (float): 지수가중 구매 활동 점수\n",
    "        sessions_seen (int): 지금까지 생성된 세션 수(해당 사용자 기준)\n",
    "        last_tier_eval_month (int): 마지막 등급 평가를 수행한 월(중복 평가 방지)\n",
    "    \"\"\"\n",
    "    user_id: int\n",
    "    tier: str\n",
    "    churned: bool = False\n",
    "    last_update: datetime = None\n",
    "    ewm_sessions: float = 0.0\n",
    "    ewm_purchases: float = 0.0\n",
    "    sessions_seen: int = 0\n",
    "    last_tier_eval_month: int = None\n",
    "\n",
    "def _decay_factor(delta_days: float, half_life: float) -> float:\n",
    "    \"\"\"\n",
    "    최근 활동치를 시간 경과에 따라 감쇠시키기 위한 지수감쇠 계수를 계산합니다.\n",
    "\n",
    "    input:\n",
    "        delta_days (float): 마지막 갱신 이후 경과일(일 단위)\n",
    "        half_life (float): 반감기(일). 해당 일수 경과 시 값이 절반으로 감소\n",
    "\n",
    "    return:\n",
    "        float: 감쇠 계수 e^(-delta_days / half_life)\n",
    "    \"\"\"\n",
    "    return math.exp(-(delta_days / half_life)) if delta_days > 0 else 1.0\n",
    "\n",
    "def update_activity_ewm(state: UserState, now: datetime, session_had_purchase: bool):\n",
    "    \"\"\"\n",
    "    세션 종료 시점에 사용자 최근활동 지표(EWMA)를 갱신합니다.\n",
    "\n",
    "    로직:\n",
    "      1) 마지막 갱신시각(last_update)와 now의 차이(Δ일)를 계산\n",
    "      2) 반감기(EWM_HALFLIFE)에 따른 감쇠계수(exp(-Δ/HL))로 기존 점수 감쇠\n",
    "      3) 이번 세션의 활동치를 가산:\n",
    "         - 세션 1회 → ewm_sessions += 1\n",
    "         - 구매 발생 시 ewm_purchases += 1\n",
    "      4) last_update와 sessions_seen 업데이트\n",
    "\n",
    "    input:\n",
    "        state (UserState): 갱신 대상 사용자 상태\n",
    "        now (datetime): 세션 종료 시각(보통 세션 마지막 이벤트 시간)\n",
    "        session_had_purchase (bool): 세션 중 구매 발생 여부\n",
    "\n",
    "    return:\n",
    "        None (state 객체 내부 값을 갱신)\n",
    "    \"\"\"\n",
    "    if state.last_update is None:\n",
    "        state.last_update = now\n",
    "\n",
    "    delta_days = (now - state.last_update).total_seconds() / 86400.0\n",
    "\n",
    "    # 1) 이전 점수 감쇠\n",
    "    for key, hl in EWM_HALFLIFE.items():\n",
    "        factor = _decay_factor(delta_days, hl)\n",
    "        if key == \"sessions\":\n",
    "            state.ewm_sessions *= factor\n",
    "        elif key == \"purchases\":\n",
    "            state.ewm_purchases *= factor\n",
    "\n",
    "    # 2) 이번 세션 활동 가산\n",
    "    state.ewm_sessions += 1.0\n",
    "    if session_had_purchase:\n",
    "        state.ewm_purchases += 1.0\n",
    "\n",
    "    # 3) 북마크 업데이트\n",
    "    state.last_update = now\n",
    "    state.sessions_seen += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 등급 전환 규칙(간결/해석가능한 룰)\n",
    "TIER_RULES = {\n",
    "    'loyal': {\n",
    "        'stay':                 {'sessions_min': 0.8, 'purchases_min': 0.15, 'p': 0.85},\n",
    "        'downgrade_to_regular': {'sessions_max': 0.5, 'purchases_max': 0.05, 'p': 0.60},\n",
    "        'downgrade_to_dormant': {'sessions_max': 0.2, 'purchases_max': 0.0, 'p': 0.15}\n",
    "    },\n",
    "    'regular': {\n",
    "        'upgrade_to_loyal':     {'sessions_min': 0.9, 'purchases_min': 0.20, 'p': 0.35},\n",
    "        'stay':                 {'sessions_min': 0.3, 'purchases_min': 0.05, 'p': 0.55},\n",
    "        'downgrade_to_dormant': {'sessions_max': 0.2, 'purchases_max': 0.02, 'p': 0.45}\n",
    "    },\n",
    "    'dormant': {\n",
    "        'recover_to_regular': {'sessions_min': 0.4, 'purchases_min': 0.05, 'p': 0.30},\n",
    "        'stay':               {'p': 0.60}\n",
    "    }\n",
    "}\n",
    "\n",
    "# 계절성 보정: 승급/복귀 확률에 월별 버프\n",
    "SEASONAL_ADJ = {\n",
    "    'upgrade_to_loyal': {11: 1.05, 12: 1.10},  # 연말 성수기\n",
    "    'recover_to_regular': {2: 1.05, 9: 1.05}   # 시즌 전환기\n",
    "}\n",
    "\n",
    "def _seasonal_boost(key: str, month: int, p: float) -> float:\n",
    "    \"\"\"\n",
    "    월별 계절성을 반영하여 특정 전환확률 p에 승수를 곱합니다.\n",
    "\n",
    "    input:\n",
    "        key (str): 보정 키(예: 'upgrade_to_loyal', 'recover_to_regular')\n",
    "        month (int): 현재 월(1~12)\n",
    "        p (float): 기본 전환 확률\n",
    "\n",
    "    return:\n",
    "        float: 보정 후 확률(최대 0.99로 캡)\n",
    "    \"\"\"\n",
    "    if key in SEASONAL_ADJ and month in SEASONAL_ADJ[key]:\n",
    "        p *= SEASONAL_ADJ[key][month]\n",
    "    return min(p, 0.99)\n",
    "\n",
    "\n",
    "def maybe_update_tier(state: UserState, now: datetime):\n",
    "    \"\"\"\n",
    "    월 경계에서 1회, 등급 전환(상향/유지/하향/복귀)을 확률적으로 평가합니다.\n",
    "\n",
    "    로직:\n",
    "      1) EWMA 지표를 간단히 정규화(sessions: capped 2.0, purchases: capped 0.5)\n",
    "      2) 현재 등급의 룰(TIER_RULES)을 참조하여 조건 충족 시 확률적으로 전환 시도\n",
    "      3) 승급/복귀에는 계절성 보정(SEASONAL_ADJ) 적용\n",
    "      4) 아무 조건에도 걸리지 않으면 기존 등급 유지\n",
    "\n",
    "    input:\n",
    "        state (UserState): 평가 대상 사용자 상태(내부 tier를 직접 갱신)\n",
    "        now (datetime): 평가 시점(월 판정에 사용)\n",
    "\n",
    "    return:\n",
    "        None (state.tier를 필요 시 변경)\n",
    "    \"\"\"\n",
    "    month = now.month\n",
    "    tier = state.tier\n",
    "    rules = TIER_RULES[tier]\n",
    "\n",
    "    # 1) 간단 정규화(폭주 방지용 상한)\n",
    "    s = min(state.ewm_sessions, 2.0)\n",
    "    p = min(state.ewm_purchases, 0.5)\n",
    "\n",
    "    # 2) 등급별 전환 로직\n",
    "    if tier == 'loyal':\n",
    "        if s <= rules['downgrade_to_dormant']['sessions_max'] and p <= rules['downgrade_to_dormant']['purchases_max']:\n",
    "            if rng.random() < rules['downgrade_to_dormant']['p']:\n",
    "                state.tier = 'dormant'; return\n",
    "        if s <= rules['downgrade_to_regular']['sessions_max'] and p <= rules['downgrade_to_regular']['purchases_max']:\n",
    "            if rng.random() < rules['downgrade_to_regular']['p']:\n",
    "                state.tier = 'regular'; return\n",
    "        return\n",
    "\n",
    "    elif tier == 'regular':\n",
    "        up = rules['upgrade_to_loyal']\n",
    "        if (s >= up['sessions_min']) and (p >= up['purchases_min']):\n",
    "            prob = _seasonal_boost('upgrade_to_loyal', month, up['p'])\n",
    "            if rng.random() < prob:\n",
    "                state.tier = 'loyal'; return\n",
    "\n",
    "        down = rules['downgrade_to_dormant']\n",
    "        if (s <= down['sessions_max']) and (p <= down['purchases_max']):\n",
    "            if rng.random() < down['p']:\n",
    "                state.tier = 'dormant'; return\n",
    "        return\n",
    "\n",
    "    else:  # dormant\n",
    "        rec = rules['recover_to_regular']\n",
    "        if (s >= rec['sessions_min']) and (p >= rec['purchases_min']):\n",
    "            prob = _seasonal_boost('recover_to_regular', month, rec['p'])\n",
    "            if rng.random() < prob:\n",
    "                state.tier = 'regular'; return\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이탈(세션 생성 중단) 확률 설정\n",
    "CHURN_CFG = {\n",
    "    # 각 세션 종료 시점 hazard(기본)\n",
    "    'hazard_per_session': {'loyal': 0.010, 'regular': 0.035, 'dormant': 0.120},\n",
    "\n",
    "    # 휴면의 \"첫 세션 직후\" 초기 이탈 확률\n",
    "    'dormant_initial_churn': 0.35,\n",
    "\n",
    "    # 세션 수가 늘수록 hazard를 올리는 램프업(최소 변경으로 반영)\n",
    "    # (threshold 세션 이상이면 factor 곱)\n",
    "    'hazard_ramp': {\n",
    "        'loyal':   [(5, 1.10), (10, 1.20)],     # 충성은 완만\n",
    "        'regular': [(3, 1.25), (6, 1.50)],      # 일반은 중간부터 가파르게\n",
    "        'dormant': [(2, 1.30), (4, 1.60)],      # 휴면은 초반부터 상승\n",
    "    },\n",
    "\n",
    "    # 상한(안정성)\n",
    "    'hazard_cap': 0.95,\n",
    "}\n",
    "\n",
    "def will_churn_after_session(user_type: str, sessions_seen: int = None) -> bool:\n",
    "    \"\"\"\n",
    "    세션 종료 시 이탈(향후 세션 생성 중단) 여부를 확률적으로 판정.\n",
    "    - dormant는 첫 세션 직후 높은 초기 이탈 확률(기본 35%) 1회 평가\n",
    "    - 기본 hazard에 sessions_seen 기반 램프업(hazard_ramp) 계수를 곱해 최종 확률로 베르누이 샘플링 (장기 리텐션 현실화)\n",
    "    input:\n",
    "        user_type: 'loyal'|'regular'|'dormant'\n",
    "        is_first_session_for_user: 첫 세션 여부\n",
    "        sessions_seen: 지금까지의 세션 수(현재 세션 포함 권장). None이면 램프업 미적용.\n",
    "    return:\n",
    "        bool: True → 이탈(이후 세션 생성 중단)\n",
    "    \"\"\"\n",
    "    # 휴면의 첫 세션 직후 초기 이탈\n",
    "    if user_type == 'dormant' and sessions_seen == 1:\n",
    "        if rng.random() < CHURN_CFG['dormant_initial_churn']:\n",
    "            return True\n",
    "\n",
    "    # 기본 hazard\n",
    "    hazard = CHURN_CFG['hazard_per_session'][user_type]\n",
    "\n",
    "    # 세션 수에 따른 램프업(옵션)\n",
    "    if sessions_seen is not None:\n",
    "        for threshold, factor in CHURN_CFG['hazard_ramp'][user_type]:\n",
    "            if sessions_seen >= threshold:\n",
    "                hazard *= factor\n",
    "\n",
    "    # 상한\n",
    "    hazard = min(hazard, CHURN_CFG['hazard_cap'])\n",
    "    return rng.random() < hazard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_category_path_uris(events: pd.DataFrame, products: pd.DataFrame, events_mask, is_page_view: bool) -> pd.Series:\n",
    "    \"\"\"\n",
    "    page_view(or search) → view_product 이벤트에 대해 카테고리 조합을 기반으로 URI를 생성하는 고성능 함수\n",
    "\n",
    "    input:\n",
    "        events: events DataFrame\n",
    "        products: products DataFrame\n",
    "        events_mask: 대상 이벤트 마스크 리스트\n",
    "        is_page_view: page_view 이벤트 여부\n",
    "\n",
    "    return:\n",
    "        pd.Series: 생성된 URI 시리즈 (index는 원래 events와 동일)\n",
    "    \"\"\"\n",
    "    # 1. 대상 마스크\n",
    "    events_pids = events.loc[events_mask, ['product_id']].copy()\n",
    "\n",
    "    # 2. 제품 정보 병합\n",
    "    target_df = events_pids.merge(products[['id', 'department', 'category', 'sub_category', 'brand']],\n",
    "                             left_on='product_id', right_on='id', how='left')\n",
    "\n",
    "    # 3. 무작위 선택 조합 전략\n",
    "    # 속성값 배열 준비\n",
    "    dept = target_df['department'].values\n",
    "    cat = target_df['category'].values\n",
    "    sub = target_df['sub_category'].values\n",
    "    brand = target_df['brand'].values\n",
    "\n",
    "    # URI 조각 저장 배열\n",
    "    length_of_target_df = len(target_df)\n",
    "    uris = np.empty(length_of_target_df, dtype=object)\n",
    "\n",
    "    # 속성 조합 패턴 생성 (속도 최적화 위해 미리 정의)\n",
    "    all_patterns = [list(c) for i in range(1, 5) for c in combinations(['department', 'category', 'sub_category', 'brand'], i)]\n",
    "    \n",
    "    if is_page_view:\n",
    "        all_patterns.remove(['sub_category'])\n",
    "        all_patterns.remove(['department'])\n",
    "        all_patterns.remove(['department', 'sub_category'])\n",
    "        all_patterns.remove(['sub_category', 'brand'])\n",
    "        all_patterns.remove(['department', 'sub_category', 'brand'])\n",
    "\n",
    "    chosen_patterns = np.random.choice(len(all_patterns), size=length_of_target_df)\n",
    "\n",
    "    # URI 생성\n",
    "    for i in range(length_of_target_df):\n",
    "        parts = []\n",
    "        pattern = all_patterns[chosen_patterns[i]]\n",
    "        \n",
    "        if 'department' in pattern:\n",
    "            parts.append(f\"department/{dept[i]}\")\n",
    "        if 'category' in pattern:\n",
    "            parts.append(f\"category/{cat[i]}\")\n",
    "        if 'sub_category' in pattern:\n",
    "            parts.append(sub[i])\n",
    "        if 'brand' in pattern:\n",
    "            parts.append(f\"brand/{brand[i]}\")\n",
    "\n",
    "        uris[i] = \"/\" + \"/\".join(parts)\n",
    "\n",
    "    # 반환: 원래 events 테이블에 맞춰 index 정렬\n",
    "    result = pd.Series(uris, index=events[events_mask].index)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_uri(events, products, promotions):\n",
    "    \"\"\"\n",
    "    이벤트 유형, 다음 이벤트, 제품 정보에 기반하여 realistic한 URI 경로를 벡터 연산으로 생성합니다.\n",
    "\n",
    "    사용자의 행동 흐름을 반영하여 각 이벤트별 서비스 내 URI 경로를 대규모 데이터셋에 빠르게 적용합니다.\n",
    "    특히 page_view 이벤트 다음이 view_product일 경우 해당 상품 카테고리 경로를 생성하고, \n",
    "    그 외의 경우에는 홈, 카테고리 또는 브랜드 페이지로 연결되도록 구성합니다.\n",
    "\n",
    "    또한 view_product, purchase, cart 관련 이벤트에는 product_id 기반의 고유 URI를 생성하며,\n",
    "    search 이벤트의 경우 인기 브랜드 및 카테고리 키워드 기반으로 검색어를 생성합니다.\n",
    "\n",
    "    input:\n",
    "        events (pd.DataFrame): 사용자 이벤트 데이터프레임\n",
    "                               반드시 'event_type', 'next_event_type', 'product_id' 등의 컬럼 포함\n",
    "        products (pd.DataFrame): 제품 정보 데이터프레임\n",
    "                                 반드시 'id', 'brand', 'department', 'category', 'sub_category' 컬럼 포함\n",
    "\n",
    "    return:\n",
    "        pd.DataFrame: URI가 포함된 사용자 이벤트 DataFrame\n",
    "                      'uri' 컬럼이 추가되며, 각 이벤트의 유형에 따라 다음과 같은 형식의 경로가 생성됩니다:\n",
    "                      - '/product/1234' (view_product)\n",
    "                      - '/department/여성/category/상의/블라우스/brand/스파오' (page_view → view_product)\n",
    "                      - '/department/남성/category/아우터' (랜덤 카테고리 page_view)\n",
    "                      - '/search?q=지오다노+셔츠' (search)\n",
    "                      - '/cart' (add_to_cart, remove_from_cart)\n",
    "                      - '/login', '/purchase' 등 (단일 이벤트 URI)\n",
    "                      - '' (click_promotion 또는 예외)\n",
    "    \"\"\"\n",
    "    events = events.copy()\n",
    "\n",
    "    # session_start URI\n",
    "    events.loc[events['event_type'] == 'session_start', 'uri'] = '/session_start'\n",
    "\n",
    "    # ① 단일 URI: signup, login, logout, checkout, purchase 등\n",
    "    simple_map = ['signup', 'login', 'logout', 'checkout', 'purchase']\n",
    "    events.loc[events['event_type'].isin(simple_map), 'uri'] = '/' + events.loc[events['event_type'].isin(simple_map), 'event_type']\n",
    "\n",
    "    # ② view_product\n",
    "    vp_mask = (events['event_type'] == 'view_product')\n",
    "    events.loc[vp_mask, 'uri'] = '/product/' + events.loc[vp_mask, 'product_id'].astype(str)\n",
    "\n",
    "    # ③-1 page_view → view_product\n",
    "    pv_vp_mask = (events['event_type'] == 'page_view') & (events['next_event_type'] == 'view_product')\n",
    "    pv_vp_uris = generate_category_path_uris(events, products, pv_vp_mask, is_page_view=True)\n",
    "    events.loc[pv_vp_uris.index, 'uri'] = pv_vp_uris\n",
    "\n",
    "    # ③-2 page_view → return or review\n",
    "    profile_event_types = ['return', 'review', 'checkout', 'remove_from_cart', 'cancel_order']\n",
    "    pv_return_review_mask = (events['event_type'] == 'page_view') & (events['next_event_type'].isin(profile_event_types))\n",
    "    events.loc[pv_return_review_mask, 'uri'] = '/profile'\n",
    "\n",
    "    # ③-3 page_view 일반\n",
    "    pv_other_mask = (events['event_type'] == 'page_view') & (~events['next_event_type'].isin(profile_event_types)) & (events['next_event_type'] != 'view_product')\n",
    "    pv_uris = generate_category_path_uris(events, products, pv_other_mask, is_page_view=True)\n",
    "    events.loc[pv_uris.index, 'uri'] = pv_uris\n",
    "\n",
    "    # ④ search 일반\n",
    "    search_mask = (events['event_type'] == 'search') & (~events['next_event_type'].isin(['view_product', 'page_view']))\n",
    "    search_uris = generate_category_path_uris(events, products, search_mask, is_page_view=False)\n",
    "    events.loc[search_uris.index, 'uri'] = search_uris\n",
    "\n",
    "    # ④-1 search → view_product\n",
    "    search_vp_mask = (events['event_type'] == 'search') & (events['next_event_type'] == 'view_product')\n",
    "    search_vp_uris = generate_category_path_uris(events, products, search_vp_mask, is_page_view=False)\n",
    "    events.loc[search_vp_uris.index, 'uri'] = search_vp_uris\n",
    "\n",
    "    # ④-2 search → page_view\n",
    "    search_pv_mask = (events['event_type'] == 'search') & (events['next_event_type'] == 'page_view')\n",
    "    search_pv_uris = generate_category_path_uris(events, products, search_pv_mask, is_page_view=False)\n",
    "    events.loc[search_pv_uris.index, 'uri'] = search_pv_uris\n",
    "\n",
    "    # ⑤ 장바구니 관련\n",
    "    cart_mask = events['event_type'].isin(['add_to_cart', 'remove_from_cart'])\n",
    "    events.loc[cart_mask, 'uri'] = '/cart'\n",
    "\n",
    "    # ⑥ 반품 또는 리뷰 작성 이벤트\n",
    "    return_review_mask = events['event_type'].isin(['return', 'review'])\n",
    "    events.loc[return_review_mask, 'uri'] = '/' + events.loc[return_review_mask, \"event_type\"]\n",
    "\n",
    "    # ⑦ 프로모션 관련\n",
    "    promotion_mask = events['event_type'].isin(['click_promotion'])\n",
    "    events.loc[promotion_mask, 'uri'] = '/timesale'\n",
    "\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_signup_date(users, events):\n",
    "    \"\"\"\n",
    "    신규 고객의 가입일(users.created_at)을 events 테이블에서 발생한 signup 이벤트 시점으로 동기화하는 함수\n",
    "\n",
    "    input:\n",
    "        users (pd.DataFrame): 사용자 정보 테이블\n",
    "                              반드시 'id', 'created_at' 컬럼 포함\n",
    "        events (pd.DataFrame): 사용자 이벤트 테이블\n",
    "                               반드시 'user_id', 'event_type', 'created_at' 컬럼 포함\n",
    "\n",
    "    return:\n",
    "        pd.DataFrame: 가입일이 갱신된 users 테이블\n",
    "    \"\"\"\n",
    "    updated_signup_dates = (\n",
    "        events.loc[events['event_type'] == 'signup', ['user_id', 'created_at']]\n",
    "        .set_index('user_id')\n",
    "        .to_dict()['created_at']\n",
    "    )\n",
    "\n",
    "    users['created_at'] = users.apply(\n",
    "        lambda x: updated_signup_dates[x['id']] if x['id'] in updated_signup_dates else x['created_at'],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    print(f\"Number of users with updated signup date: {len(updated_signup_dates)}\")\n",
    "    \n",
    "    return users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed & Faker 설정\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "faker = Faker(\"ko_KR\")\n",
    "\n",
    "# 데이터 로드\n",
    "users_df = pd.read_csv(\"./data/users.csv\", parse_dates=['birth', 'created_at'])\n",
    "visitor_df = pd.read_csv(\"./data/visitor_stats_by_city_month.csv\")\n",
    "promotion_df = pd.read_csv(\"./data/promotions.csv\", parse_dates=['start_date', 'end_date'])\n",
    "\n",
    "# 시뮬레이션 설정\n",
    "start_date = datetime(2022, 1, 1)\n",
    "end_date = datetime(2025, 1, 1)\n",
    "\n",
    "# 사용자 유형 분포 설정 및 유형에 따른 세션 생성 간격(방문 간격) 설정\n",
    "num_users = users_df.shape[0]\n",
    "users_df['user_type'] = random.choices(['loyal', 'regular', 'dormant'], weights=[0.05, 0.10, 0.85], k=num_users)\n",
    "\n",
    "# 메타 데이터 설정\n",
    "BROWSERS_PC = [\"Chrome\", \"Edge\", \"Whale\", \"Safari\"]\n",
    "BROWSERS_MOBILE = [\"Chrome\", \"Edge\", \"Safari\", \"Samsung Internet\"]\n",
    "\n",
    "EVENT_TYPES = [\n",
    "    \"session_start\", \"signup\", \"login\", \"logout\", \"view_product\", \"page_view\",\n",
    "    \"scroll\", \"search\", \"click_promotion\", \"add_to_cart\", \"remove_from_cart\",\n",
    "    \"checkout\", \"purchase\"\n",
    "]\n",
    "\n",
    "# 확률 범위 설정 (디바이스, 브라우저, 트래픽 소스)\n",
    "device_range = {\"Mobile\": (0.75, 0.85), \"PC\": (0.15, 0.25)}\n",
    "browser_range = {\n",
    "    \"Chrome\": (0.5, 0.6), \"Safari\": (0.18, 0.25), \"Samsung Internet\": (0.1, 0.15),\n",
    "    \"Edge\": (0.02, 0.05), \"Whale\": (0.01, 0.03)\n",
    "}\n",
    "traffic_range_base = {\n",
    "    \"direct\": (0.15, 0.25), \"organic_search\": (0.35, 0.45), \"paid_search\": (0.05, 0.1),\n",
    "    \"facebook\": (0.05, 0.1), \"instagram\": (0.05, 0.1), \"kakao\": (0.03, 0.07),\n",
    "    \"email\": (0.01, 0.03), \"referral\": (0.02, 0.05)\n",
    "}\n",
    "\n",
    "six_hours = timedelta(hours=6)\n",
    "fifteen_days = timedelta(days=15)\n",
    "\n",
    "events = []\n",
    "states = {}  # user_id -> UserState\n",
    "event_id = 1\n",
    "new_users_signed = set()\n",
    "namespace = uuid.NAMESPACE_DNS\n",
    "\n",
    "# 고객 행동 데이터 생성\n",
    "for idx, row in users_df.iterrows():\n",
    "    user_id = row[\"id\"]\n",
    "    user_type = row[\"user_type\"]\n",
    "    signup_date = pd.to_datetime(row[\"created_at\"])\n",
    "    is_new_user_overall = (signup_date >= start_date)\n",
    "    num_sessions = 0  # 고객별 생성된 세션의 수 초기화\n",
    "\n",
    "    # 고객 상태 초기화\n",
    "    states[user_id] = UserState(user_id=user_id, tier=user_type, last_update=None)\n",
    "\n",
    "    # 첫 세션 시작 시간 설정\n",
    "    if is_new_user_overall:\n",
    "        # 신규 유저: 가입 시점 직전에 첫 세션 시작\n",
    "        session_time = signup_date - timedelta(seconds=random.randint(1, 600))\n",
    "    else:\n",
    "        # 기존 유저: 시뮬레이션 시작 후 첫 한 달 내의 랜덤 시점에서 세션 시작\n",
    "        session_time = start_date + timedelta(days=random.randint(0, 30))\n",
    "\n",
    "    # 반품 또는 리뷰 작성 이벤트 생성 여부 초기화\n",
    "    inserted_type = None\n",
    "\n",
    "    # 유저별 여러 세션 생성\n",
    "    while session_time < end_date:\n",
    "        session_id = 'e-' + str(uuid.uuid5(namespace, str(event_id)))[:12]\n",
    "        \n",
    "        state = states[user_id]\n",
    "\n",
    "        # 고객이 이탈했으면 세션 생성 중단\n",
    "        if state.churned:\n",
    "            break\n",
    "\n",
    "        # 세션 시작 시간 설정\n",
    "        current_time = session_time\n",
    "\n",
    "        # 세션별 디바이스, 브라우저, 트래픽 소스 확률 분포 생성 및 선택\n",
    "        device_probs = generate_prob_from_range(device_range)\n",
    "        browser_probs = generate_prob_from_range(browser_range)\n",
    "        base_traffic_probs = generate_prob_from_range(traffic_range_base)\n",
    "        traffic_probs = adjust_traffic_for_month(base_traffic_probs, session_time.month)\n",
    "\n",
    "        device = np.random.choice(list(device_probs.keys()), p=list(device_probs.values()))\n",
    "        traffic_source = np.random.choice(list(traffic_probs.keys()), p=list(traffic_probs.values()))\n",
    "        \n",
    "        possible_browsers = BROWSERS_MOBILE if device == \"Mobile\" else BROWSERS_PC\n",
    "        possible_browsers = [b for b in possible_browsers if b in browser_probs]\n",
    "        browser_weights = np.array([browser_probs[b] for b in possible_browsers])\n",
    "        browser_weights /= browser_weights.sum()\n",
    "        browser = np.random.choice(possible_browsers, p=browser_weights)\n",
    "\n",
    "        ip_address = faker.ipv4_public()\n",
    "        if random.random() < 0.7:\n",
    "            address = row['address']\n",
    "        else:\n",
    "            address = generate_address_by_visitor_stats(current_time, visitor_df) \n",
    "\n",
    "        # 세션 내 이벤트 시퀀스 생성\n",
    "        ## 신규 유저 여부 판단\n",
    "        user_is_new_for_session = False\n",
    "        if is_new_user_overall and user_id not in new_users_signed:\n",
    "            user_is_new_for_session = True\n",
    "            new_users_signed.add(user_id)\n",
    "\n",
    "        # 세션 내 이벤트 목록 생성\n",
    "        session_events = generate_session_events(session_id, user_id, user_is_new_for_session, traffic_source, current_time, promotion_df, forced_event_type=inserted_type)\n",
    "\n",
    "        # 세션 이벤트들 추가 (session_start 이벤트 + 생성된 session_events 목록)\n",
    "        # 세션의 시작 이벤트 session_start 삽입\n",
    "        sequence = 1\n",
    "\n",
    "        events.append({\n",
    "            \"id\": event_id,\n",
    "            \"user_id\": user_id,\n",
    "            \"session_id\": session_id,\n",
    "            \"sequence\": sequence,\n",
    "            \"event_type\": \"session_start\",\n",
    "            \"created_at\": current_time,\n",
    "            \"device\": device,\n",
    "            \"browser\": browser,\n",
    "            \"traffic_source\": traffic_source,\n",
    "            \"ip_address\": ip_address,\n",
    "            \"address\": address\n",
    "        })\n",
    "\n",
    "        event_id += 1\n",
    "        prev_event = \"session_start\"\n",
    "\n",
    "        # 나머지 세션 이벤트 처리\n",
    "        for event_type in session_events:\n",
    "            # 이전 이벤트 대비 시간 간격 계산\n",
    "            gap = event_time_gap(prev_event, event_type)\n",
    "            current_time += timedelta(seconds=float(gap))\n",
    "\n",
    "            sequence += 1\n",
    "\n",
    "            event_data = {\n",
    "                \"id\": event_id,\n",
    "                \"user_id\": user_id,\n",
    "                \"session_id\": session_id,\n",
    "                \"sequence\": sequence,\n",
    "                \"event_type\": event_type,\n",
    "                \"created_at\": current_time,\n",
    "                \"device\": device,\n",
    "                \"browser\": browser,\n",
    "                \"traffic_source\": traffic_source,\n",
    "                \"ip_address\": ip_address,\n",
    "                \"address\": address\n",
    "            }\n",
    "\n",
    "            event_id += 1\n",
    "            events.append(event_data)\n",
    "            prev_event = event_type\n",
    "\n",
    "        # --------------- 세션 종료 후: 활동지표 갱신 → 등급 평가(월 1회) → 이탈 판정 --------------- #\n",
    "        # 유저별 생성된 세션 수 증가\n",
    "        num_sessions += 1\n",
    "        \n",
    "        # 방금 생성한 세션에 구매 발생 여부\n",
    "        has_purchase_session = ('purchase' in session_events) & ('cancel_order' not in session_events)\n",
    "        \n",
    "        # 세션 종료 시각\n",
    "        session_end_time = current_time\n",
    "        \n",
    "        # 활동지표 갱신\n",
    "        update_activity_ewm(state, now=session_end_time, session_had_purchase=has_purchase_session)\n",
    "        \n",
    "        # 등급 평가\n",
    "        maybe_update_tier(state, now=session_end_time)\n",
    "\n",
    "        # 이탈 여부 판정\n",
    "        if will_churn_after_session(state.tier, sessions_seen=num_sessions):\n",
    "            state.churned = True\n",
    "            break\n",
    "\n",
    "        # 다음 세션까지의 간격 결정\n",
    "        gap_days = sample_session_gap_days(state.tier)\n",
    "\n",
    "        # --------------------- return or review 이벤트 생성 여부 설정 --------------------- #\n",
    "\n",
    "        # 이전 세션에서 구매가 발생했을때 일정 확률에 따라 return or review 이벤트 생성\n",
    "        if has_purchase_session:\n",
    "            rand_val = random.random()\n",
    "            if rand_val < 0.10:\n",
    "                inserted_type = 'return'\n",
    "            elif rand_val < 0.13:\n",
    "                inserted_type = 'review'\n",
    "            else:\n",
    "                inserted_type = None\n",
    "        else:\n",
    "            inserted_type = None\n",
    "        \n",
    "        limit_date = pd.Timestamp(session_time + fifteen_days).normalize().to_pydatetime()  # return or review가 발생할 수 있는 제한 시간(세션 생성일부터 15일 후 00시까지)\n",
    "\n",
    "        # 다음 세션 생성 시간 계산\n",
    "        session_time = current_time + gap_days\n",
    "        \n",
    "        is_possible_return_or_review = (session_time < limit_date)  # 세션 생성일부터 15일 이내 인 경우\n",
    "\n",
    "        if gap_days < six_hours:\n",
    "            inserted_type = None\n",
    "            continue\n",
    "\n",
    "        # ----------------------- return or review 이벤트 생성 로직 ----------------------- #\n",
    "\n",
    "        # 이전 세션에서 구매가 발생했을 경우 일정 확률에 따라 다음 세션에서 반품 또는 리뷰 작성 이벤트 발생\n",
    "        ## inserted_type이 있고, 다음 세션 간격이 15일 초과인 경우\n",
    "        ### 이전 세션과 다음 세션 사이(이전 세션 발생 후 15일 이내)에 반품 또는 리뷰 작성 세션 추가 (세션 간격 gap_days가 15일 이내일 경우, 다음 세션에서 반품 또는 리뷰 작성 이벤트 생성)\n",
    "        if inserted_type and not is_possible_return_or_review:\n",
    "            # 반품 또는 리뷰 작성 이벤트 생성\n",
    "            ins_current_time = current_time + timedelta(days=random.randint(1, 14))\n",
    "            ins_session_time = ins_current_time\n",
    "            \n",
    "            # 세션 생성 시간이 시뮬레이션 종료 시간 이전인 경우에만 세션 생성\n",
    "            if ins_current_time < end_date:\n",
    "                ins_session_id = 'e-' + str(uuid.uuid5(namespace, str(event_id)))[:12]\n",
    "                user_is_new_for_ins = False\n",
    "\n",
    "                # 새 세션의 디바이스, 브라우저, 트래픽 소스 무작위 선택\n",
    "                device = np.random.choice(list(device_probs.keys()), p=list(device_probs.values()))\n",
    "                traffic_source = np.random.choice(list(traffic_probs.keys()), p=list(traffic_probs.values()))\n",
    "\n",
    "                possible_browsers = BROWSERS_MOBILE if device == \"Mobile\" else BROWSERS_PC\n",
    "                possible_browsers = [b for b in possible_browsers if b in browser_probs]\n",
    "                browser_weights = np.array([browser_probs[b] for b in possible_browsers])\n",
    "                browser_weights /= browser_weights.sum()\n",
    "                browser = np.random.choice(possible_browsers, p=browser_weights)\n",
    "\n",
    "                ip_address = faker.ipv4_public()\n",
    "                if random.random() < 0.7:\n",
    "                    address = row['address']\n",
    "                else:\n",
    "                    address = generate_address_by_visitor_stats(ins_current_time, visitor_df) \n",
    "\n",
    "                # 강제 이벤트 타입을 지정하여 세션 이벤트 생성\n",
    "                inserted_events = generate_session_events(ins_session_id, user_id, user_is_new_for_ins, traffic_source, ins_current_time, promotion_df, forced_event_type=inserted_type)     \n",
    "\n",
    "                # 세션 이벤트들 추가 (session_start 이벤트 + 생성된 session_events 목록)\n",
    "                # 세션의 시작 이벤트 session_start 삽입\n",
    "                sequence = 1\n",
    "\n",
    "                events.append({\n",
    "                    \"id\": event_id,\n",
    "                    \"user_id\": user_id,\n",
    "                    \"session_id\": ins_session_id,\n",
    "                    \"sequence\": sequence,\n",
    "                    \"event_type\": \"session_start\",\n",
    "                    \"created_at\": ins_current_time,\n",
    "                    \"device\": device,\n",
    "                    \"browser\": browser,\n",
    "                    \"traffic_source\": traffic_source,\n",
    "                    \"ip_address\": ip_address,\n",
    "                    \"address\": address\n",
    "                })\n",
    "\n",
    "                event_id += 1\n",
    "                prev_event = \"session_start\"\n",
    "\n",
    "                # 나머지 세션 이벤트 처리\n",
    "                for event_type in inserted_events:\n",
    "                    # 이전 이벤트 대비 시간 간격 계산\n",
    "                    gap = event_time_gap(prev_event, event_type)\n",
    "                    ins_current_time += timedelta(seconds=float(gap))\n",
    "\n",
    "                    sequence += 1\n",
    "                    \n",
    "                    event_data = {\n",
    "                        \"id\": event_id,\n",
    "                        \"user_id\": user_id,\n",
    "                        \"session_id\": ins_session_id,\n",
    "                        \"sequence\": sequence,\n",
    "                        \"event_type\": event_type,\n",
    "                        \"created_at\": ins_current_time,\n",
    "                        \"device\": device,\n",
    "                        \"browser\": browser,\n",
    "                        \"traffic_source\": traffic_source,\n",
    "                        \"ip_address\": ip_address,\n",
    "                        \"address\": address\n",
    "                    }\n",
    "\n",
    "                    event_id += 1\n",
    "                    events.append(event_data)\n",
    "                    prev_event = event_type\n",
    "\n",
    "                # 유저별 생성된 세션 수 증가\n",
    "                num_sessions += 1\n",
    "\n",
    "                # 세션 종료 시각\n",
    "                ins_session_end_time = ins_current_time\n",
    "\n",
    "                # 방금 생성한 세션에 구매 발생 여부\n",
    "                has_purchase_session = ('purchase' in inserted_events) & ('cancel_order' not in inserted_events)\n",
    "                \n",
    "                # 활동지표 갱신\n",
    "                update_activity_ewm(state, now=ins_session_end_time, session_had_purchase=has_purchase_session)\n",
    "\n",
    "                # 이탈 여부 판정\n",
    "                if will_churn_after_session(state.tier, sessions_seen=num_sessions):\n",
    "                    state.churned = True\n",
    "                    break\n",
    "\n",
    "                # 이전 세션에서 구매가 발생했을때 및 일정 확률에 따라 return or review 이벤트 생성\n",
    "                gap_end_to_start = (session_time - ins_session_end_time)  # 다음 세션의 시작 시간과 이전 세션의 종료 시간 간격\n",
    "                gap_start_to_start = (session_time - ins_session_time)  # 다음 세션의 시작 시간과 이전 세션의 시작 시간 간격\n",
    "\n",
    "                is_possible_return_or_review = (gap_end_to_start > six_hours) & (gap_start_to_start < fifteen_days)\n",
    "\n",
    "                if has_purchase_session and is_possible_return_or_review:\n",
    "                    rand_val = random.random()\n",
    "                    if rand_val < 0.10:\n",
    "                        inserted_type = 'return'\n",
    "                    elif rand_val < 0.13:\n",
    "                        inserted_type = 'review'\n",
    "                    else:\n",
    "                        inserted_type = None\n",
    "                else:\n",
    "                    inserted_type = None\n",
    "\n",
    "        # -------------------------------------------------------------------------------- #\n",
    "\n",
    "\n",
    "# 결과 DataFrame 생성\n",
    "events_df = pd.DataFrame(events)\n",
    "\n",
    "print(events_df.info())\n",
    "events_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## URI 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df = pd.read_csv(\"./data/products.csv\")\n",
    "product_ids = products_df['id'].tolist()\n",
    "\n",
    "# 1. search or page_view → view_product uri 생성을 위한 product_id 처리\n",
    "## 1-1. product_id 랜덤 생성 (view_product에만)\n",
    "events_df = events_df.sort_values([\"user_id\", \"session_id\", \"created_at\"]).reset_index(drop=True)\n",
    "events_df[\"next_event_type\"] = events_df.groupby([\"user_id\", \"session_id\"])[\"event_type\"].shift(-1)\n",
    "\n",
    "view_product_mask = (events_df[\"event_type\"] == \"view_product\")\n",
    "events_df.loc[view_product_mask, \"product_id\"] = np.random.choice(product_ids, size=view_product_mask.sum())\n",
    "\n",
    "## 1-2. search or page_view → view_product 흐름에서 product_id 복사\n",
    "search_pv_vp_mask = (events_df[\"event_type\"].isin([\"page_view\", \"search\"])) & (events_df[\"next_event_type\"] == \"view_product\")\n",
    "vp_indices = events_df[search_pv_vp_mask].index\n",
    "vp_next_indices = vp_indices + 1\n",
    "\n",
    "# 1-3. next row가 view_product인지 확인 (안정성 보강)\n",
    "valid_vp_idx = vp_next_indices[vp_next_indices < len(events_df)]\n",
    "valid_search_pv_idx = vp_indices[vp_next_indices < len(events_df)]\n",
    "\n",
    "## 1-4. product_id 복사\n",
    "events_df.loc[valid_search_pv_idx, \"product_id\"] = events_df.loc[valid_vp_idx, \"product_id\"].values\n",
    "\n",
    "\n",
    "# 2. search → page_view uri 생성을 위한 product_id 처리\n",
    "## 2-1. search → page_view 마스크\n",
    "search_to_pv_mask = (events_df[\"event_type\"] == \"search\") & (events_df[\"next_event_type\"] == \"page_view\")\n",
    "\n",
    "search_indices = events_df[search_to_pv_mask].index\n",
    "pv_indices = search_indices + 1\n",
    "\n",
    "# 인덱스 범위 내 유효성 필터링\n",
    "valid_idx_mask = pv_indices < len(events_df)\n",
    "valid_search_idx = search_indices[valid_idx_mask]\n",
    "valid_pv_idx = pv_indices[valid_idx_mask]\n",
    "\n",
    "## 2-2. page_view의 product_id가 없는 경우 → page_view에 랜덤 생성\n",
    "no_product_id_mask = events_df.loc[valid_pv_idx, \"product_id\"].isna()\n",
    "missing_pv_idx = valid_pv_idx[no_product_id_mask]\n",
    "\n",
    "events_df.loc[missing_pv_idx, \"product_id\"] = np.random.choice(\n",
    "    product_ids, size=len(missing_pv_idx)\n",
    ")\n",
    "\n",
    "## 2-3. page_view의 product_id → search에 복사\n",
    "events_df.loc[valid_search_idx, \"product_id\"] = events_df.loc[valid_pv_idx, \"product_id\"].values\n",
    "\n",
    "# 3. 그 외 search의 uri 생성을 위한 product_id 처리\n",
    "search_no_pid_mask = (events_df[\"event_type\"] == \"search\") & (events_df[\"product_id\"].isna())\n",
    "events_df.loc[search_no_pid_mask, \"product_id\"] = np.random.choice(\n",
    "    product_ids, size=search_no_pid_mask.sum()\n",
    ")\n",
    "\n",
    "# 4. 그 외 page_view의 uri 생성을 위한 product_id 처리\n",
    "pv_no_pid_mask = (events_df[\"event_type\"] == \"page_view\") & (events_df[\"product_id\"].isna())\n",
    "events_df.loc[pv_no_pid_mask, \"product_id\"] = np.random.choice(\n",
    "    product_ids, size=pv_no_pid_mask.sum()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df = generate_uri(events_df, products_df, promotion_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df.drop(columns=[\"next_event_type\", \"product_id\"], inplace=True)\n",
    "\n",
    "events_df['created_at'] = events_df['created_at'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "events_df['created_at'] = pd.to_datetime(events_df['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_end_date_session_ids = events_df.loc[events_df['created_at'] > end_date, \"session_id\"].unique()\n",
    "events_df = events_df[~events_df['session_id'].isin(over_end_date_session_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df = events_df.sort_values(by=['id']).reset_index(drop=True)\n",
    "events_df.to_csv(\"./data/events.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## users 신규 고객의 가입일 갱신(events에서 signup 이벤트가 발생한 시점)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'users_df' in globals():\n",
    "    \n",
    "    if \"user_type\" in users_df.columns:\n",
    "        users_df = users_df.drop(columns=['user_type'])\n",
    "else:\n",
    "    users_df = pd.read_csv(\"./data/users.csv\", parse_dates=['birth', 'created_at'])\n",
    "\n",
    "users_df = update_signup_date(users_df, events_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df.to_csv('./data/users.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Order_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. events_cart_df 생성 \n",
    "\n",
    "# seed 설정\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# 데이터 로드 \n",
    "events_df = pd.read_csv(\"./data/events.csv\", parse_dates=[\"created_at\"])\n",
    "\n",
    "# Step 1: 주요 이벤트(add_to_cart, purchase, click_promotion, view_product)만 추출\n",
    "filtered_df = events_df[events_df['event_type'].isin(['add_to_cart', 'purchase', 'click_promotion', 'view_product'])].copy()\n",
    "filtered_df['product_id'] = filtered_df[\"uri\"].str.extract(r'/product/([^/]+)$')\n",
    "\n",
    "# 이전 이벤트 정보 추가\n",
    "filtered_df['prev_event_type'] = filtered_df.groupby(\"user_id\")[\"event_type\"].shift(1)\n",
    "filtered_df['prev_product_id'] = filtered_df.groupby(\"user_id\")[\"product_id\"].shift(1)\n",
    "filtered_df['prev2_event_type'] = filtered_df.groupby(\"user_id\")[\"event_type\"].shift(2)\n",
    "\n",
    "\n",
    "# 장바구니/구매 이벤트(add_to_cart, purchase) 필터링 및 프로모션 여부 판단\n",
    "cart_df = filtered_df[filtered_df['event_type'].isin(['add_to_cart', 'purchase'])].copy()\n",
    "cart_df['is_promotion'] = filtered_df['prev2_event_type'] == 'click_promotion'\n",
    "\n",
    "# 컬럼 정리\n",
    "keep_cols = ['id', 'user_id', 'session_id', 'event_type',\n",
    "             'created_at', 'prev_event_type', 'prev_product_id', 'is_promotion']\n",
    "cart_df = cart_df[keep_cols]\n",
    "\n",
    "# Step 2: remove_from_cart 처리\n",
    "remove_df = events_df[events_df['event_type'] == 'remove_from_cart'].copy()\n",
    "remove_df['prev_event_type'] = None\n",
    "remove_df['prev_product_id'] = None\n",
    "remove_df['is_promotion'] = False\n",
    "\n",
    "remove_df = remove_df[keep_cols]\n",
    "\n",
    "# Step 3: 테이블 병합 및 정렬 \n",
    "events_cart_df = pd.concat([cart_df, remove_df], axis=0)\n",
    "events_cart_df = events_cart_df.sort_values(['user_id', 'created_at']).reset_index(drop=True)\n",
    "\n",
    "# 다음 이벤트 정보 추가 \n",
    "events_cart_df['next_event_type'] = events_cart_df.groupby(\"user_id\")[\"event_type\"].shift(-1)\n",
    "\n",
    "# Step 4: 장바구니 및 구매 컬럼 생성\n",
    "events_cart_df['cart'] = None\n",
    "events_cart_df['purchased_products'] = None\n",
    "\n",
    "# Step 5: 사용자별 장바구니 및 구매 처리\n",
    "user_groups = events_cart_df.groupby('user_id', sort=False).groups  \n",
    "\n",
    "\n",
    "empty_cart_remove_indices = [] # 장바구니가 비었을 때 remove_from_cart 이벤트 인덱스\n",
    "\n",
    "empty_cart_purchase_indices = []  # 장바구니가 비었을 때 purchase 이벤트 인덱스\n",
    "\n",
    "\n",
    "for user_id, indices in user_groups.items():\n",
    "    cart_state = {'general': [], 'timesale': []}\n",
    "\n",
    "    for idx in indices:\n",
    "        row = events_cart_df.loc[idx]\n",
    "        event = row['event_type']\n",
    "        product = row['prev_product_id']\n",
    "        is_promo = row['is_promotion']\n",
    "        prev_event = row['prev_event_type']\n",
    "        next_event = row['next_event_type']\n",
    "\n",
    "        if event == 'add_to_cart':\n",
    "            key = 'timesale' if is_promo else 'general'\n",
    "            cart_state[key].append(product)\n",
    "            events_cart_df.at[idx, 'cart'] = copy.deepcopy(cart_state)\n",
    "\n",
    "        elif event == 'remove_from_cart':\n",
    "            combined = cart_state['general'] + cart_state['timesale']\n",
    "        \n",
    "            if len(combined) > 0:  # 빈 장바구니 방지\n",
    "                if next_event == 'purchase' and len(combined) > 1:\n",
    "                    max_removable = len(combined) - 1 # 다음 이벤트가 purchase면 최소 1개 남기기\n",
    "                    remove_n = random.randint(1, max_removable)\n",
    "                else: \n",
    "                    remove_n = random.randint(1, len(combined)) # 이외 이벤트는 전부 제거 가능\n",
    "        \n",
    "                to_remove = random.sample(combined, k=remove_n)\n",
    "                cart_state['general'] = [p for p in cart_state['general'] if p not in to_remove]\n",
    "                cart_state['timesale'] = [p for p in cart_state['timesale'] if p not in to_remove]\n",
    "        \n",
    "            else:\n",
    "                empty_cart_remove_indices.append(idx)  # 빈 장바구니였던 경우 기록\n",
    "        \n",
    "            events_cart_df.at[idx, 'cart'] = copy.deepcopy(cart_state)\n",
    "\n",
    "        elif event == 'purchase':\n",
    "            purchased = {'general': [], 'timesale': []}\n",
    "            if prev_event == 'view_product':\n",
    "                # 직접 구매 상품 \n",
    "                if is_promo:\n",
    "                    purchased['timesale'] = [product]\n",
    "                else:\n",
    "                    purchased['general'] = [product]\n",
    "            else:\n",
    "                # 장바구니 기반 구매\n",
    "                combined = cart_state['general'] + cart_state['timesale']\n",
    "                if combined:                                                   \n",
    "                    if next_event == 'remove_from_cart' and len(combined) > 1: # 다음 이벤트가 remove_from_cart면 최소 1개 남기고 구매\n",
    "                        max_purchase = len(combined) - 1  \n",
    "                        purchase_n = random.randint(1, max_purchase)\n",
    "                    else:                                                         \n",
    "                        purchase_n = random.randint(1, len(combined)) # 이외 이벤트는 1 ~ 전체 구매\n",
    "\n",
    "                    to_purchase = random.sample(combined, k=purchase_n)\n",
    "                    purchased['general'] = [p for p in to_purchase if p in cart_state['general']]\n",
    "                    purchased['timesale'] = [p for p in to_purchase if p in cart_state['timesale']]\n",
    "\n",
    "                    # 장바구니에서 구매된 상품 제거\n",
    "                    cart_state['general'] = [p for p in cart_state['general'] if p not in purchased['general']]\n",
    "                    cart_state['timesale'] = [p for p in cart_state['timesale'] if p not in purchased['timesale']]\n",
    "                else:\n",
    "                    empty_cart_purchase_indices.append(idx)  # 빈 장바구니였던 경우 기록\n",
    "                    \n",
    "\n",
    "            events_cart_df.at[idx, 'purchased_products'] = purchased\n",
    "            events_cart_df.at[idx, 'cart'] = copy.deepcopy(cart_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 \n",
    "\n",
    "\n",
    "# Step 1. purchased_products 컬럼 기준으로 구매 상품 분해\n",
    "\n",
    "# 구매 정보가 있는 행만 필터링\n",
    "events_cart_df = events_cart_df.dropna(subset=['purchased_products']).copy()\n",
    "\n",
    "# 일반 상품 (general) 추출\n",
    "general_df = events_cart_df[['user_id', 'id', 'session_id', 'event_type', 'created_at']].copy()\n",
    "general_df['product_id'] = events_cart_df['purchased_products'].apply(lambda x: x.get('general', []))\n",
    "general_df = general_df[general_df['product_id'].apply(lambda x: len(x) > 0)]\n",
    "general_df['general'] = True\n",
    "general_df['timesale'] = False\n",
    "general_df = general_df.explode('product_id')\n",
    "\n",
    "# 타임세일 상품 (timesale) 추출\n",
    "timesale_df = events_cart_df[['user_id', 'id', 'session_id', 'event_type', 'created_at']].copy()\n",
    "timesale_df['product_id'] = events_cart_df['purchased_products'].apply(lambda x: x.get('timesale', []))\n",
    "timesale_df = timesale_df[timesale_df['product_id'].apply(lambda x: len(x) > 0)]\n",
    "timesale_df['general'] = False\n",
    "timesale_df['timesale'] = True\n",
    "timesale_df = timesale_df.explode('product_id')\n",
    "\n",
    "# general / timesale 구매 상품 병합\n",
    "purchased_df = pd.concat([general_df, timesale_df], ignore_index=True)\n",
    "purchased_df = purchased_df.dropna(subset=['product_id'])\n",
    "\n",
    "\n",
    "# Step 2. return, cancel 이벤트 추출 및 복사\n",
    "\n",
    "# 필요한 이벤트만 복사\n",
    "events_copy_df = events_df[['id', 'user_id', 'session_id', 'event_type', 'created_at']].copy()\n",
    "return_df = events_copy_df[events_copy_df['event_type'] == 'return'].copy()\n",
    "cancel_df = events_copy_df[events_copy_df['event_type'] == 'cancel_order'].copy()\n",
    "\n",
    "# purchase/return 타임스탬프 컬럼 추가\n",
    "purchase_df = purchased_df[purchased_df['event_type'] == 'purchase'].copy()\n",
    "purchase_df['created_at_purchase'] = purchase_df['created_at']\n",
    "return_df['created_at_return'] = return_df['created_at']\n",
    "\n",
    "\n",
    "return_matched = []\n",
    "for user_id, return_group in return_df.groupby(\"user_id\"):\n",
    "    if user_id not in purchase_df['user_id'].values:\n",
    "        continue\n",
    "\n",
    "    # 해당 유저의 purchase 데이터 정렬\n",
    "    user_purchase_df = purchase_df[purchase_df['user_id'] == user_id].sort_values('created_at_purchase')\n",
    "\n",
    "    for _, return_row in return_group.iterrows():\n",
    "        return_time = return_row['created_at_return']\n",
    "\n",
    "        # 조건: return 발생 기준 1~15일 전 사이의 purchase 모두 포함\n",
    "        start_time = (return_time - timedelta(days=15)).normalize()  # 15일 전 자정\n",
    "        end_time = return_time - timedelta(hours=6)                   # return 이벤트 생성 시점 6시간 전 \n",
    "\n",
    "        # 해당 범위에 있는 모든 purchase\n",
    "        valid_purchases = user_purchase_df[\n",
    "            (user_purchase_df['created_at_purchase'] >= start_time) &\n",
    "            (user_purchase_df['created_at_purchase'] <= end_time)\n",
    "        ]\n",
    "        # 여러 purchase에 동일한 return_row를 복제하여 연결\n",
    "        for _, purchase_row in valid_purchases.iterrows():\n",
    "            merged_row = return_row.to_dict()\n",
    "            for col in ['id', 'event_type', 'created_at', 'product_id']:\n",
    "                merged_row[f'{col}_purchase'] = purchase_row.get(col)\n",
    "            return_matched.append(merged_row)\n",
    "\n",
    "# 결과 DataFrame으로 변환\n",
    "return_link_df = pd.DataFrame(return_matched)\n",
    "\n",
    "# purchase_df에 return 정보 병합\n",
    "purchase_return_df = pd.merge(purchase_df, return_link_df, how='left', left_on=['id', 'product_id'], right_on=['id_purchase', 'product_id_purchase'])\n",
    "\n",
    "# 컬럼 정리\n",
    "columns = ['user_id_x', 'id_x', 'event_type_x', 'created_at_x', 'product_id',\n",
    "           'general', 'timesale', 'id_y', 'event_type_y', 'created_at_return']\n",
    "purchase_return_df = purchase_return_df[columns]\n",
    "\n",
    "# 컬럼명 정리\n",
    "purchase_return_df = purchase_return_df.rename(columns={\n",
    "    'user_id_x': 'user_id',\n",
    "    'id_x': 'id_purchase',\n",
    "    'event_type_x': 'event_type_purchase',\n",
    "    'created_at_x': 'created_at_purchase',\n",
    "    'id_y': 'id_return',\n",
    "    'event_type_y': 'event_type_return'\n",
    "})\n",
    "\n",
    "\n",
    "# Step 4. cancel - purchase 연결 (merge_asof)\n",
    "\n",
    "# cancel 이벤트에 타임스탬프 복사\n",
    "cancel_df['created_at_cancel'] = cancel_df['created_at']\n",
    "\n",
    "cancel_matched = []\n",
    "for user_id, cancel_group in cancel_df.groupby(\"user_id\"):\n",
    "    if user_id not in purchase_return_df['user_id'].values:\n",
    "        continue\n",
    "\n",
    "    # 유저별 purchase 정렬 후 merge_asof\n",
    "    user_purchase_df = purchase_df[purchase_df['user_id'] == user_id].copy()\n",
    "    merged_df = pd.merge_asof(\n",
    "        cancel_group.sort_values('created_at_cancel'),\n",
    "        user_purchase_df.sort_values('created_at_purchase'),\n",
    "        by='user_id',\n",
    "        left_on='created_at_cancel',\n",
    "        right_on='created_at_purchase',\n",
    "        direction='backward'\n",
    "    )\n",
    "    cancel_matched.append(merged_df)\n",
    "\n",
    "# cancel → purchase 매핑 결과 DataFrame 생성\n",
    "cancel_link_df = pd.concat(cancel_matched, ignore_index=True)\n",
    "cancel_link_df = cancel_link_df[['id_y', 'id_x', 'event_type_x', 'created_at_cancel']]\n",
    "cancel_link_df = cancel_link_df.rename(columns={\n",
    "    'id_y': 'id_purchase',\n",
    "    'id_x': 'id_cancel',\n",
    "    'event_type_x': 'event_type_cancel'\n",
    "})\n",
    "\n",
    "# purchase_return_df에 cancel 정보 병합\n",
    "purchase_return_cancel_df = pd.merge(purchase_return_df, cancel_link_df, how='left', on='id_purchase')\n",
    "\n",
    "\n",
    "# Step 5. order_items_df 생성\n",
    "order_items_df = purchase_return_cancel_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 \n",
    "\n",
    "\n",
    "# Step 1. 상태 및 시간 컬럼 초기화\n",
    "# status, shipped_at, delivered_at, returned_at 생성 \n",
    "order_items_df['status'] = None\n",
    "order_items_df['shipped_at'] = pd.NaT\n",
    "order_items_df['delivered_at'] = pd.NaT\n",
    "order_items_df['returned_at'] = pd.NaT\n",
    "end_date = datetime(2025, 1, 1)\n",
    "\n",
    "\n",
    "# Step 2. 상태 (status) 설정\n",
    "# Returned 상태 무작위 지정 (반품 이벤트 그룹 중 일부만 선택적으로 Returned)\n",
    "returned_mask = order_items_df['event_type_return'].notna()\n",
    "for _, group_df in order_items_df.loc[returned_mask].groupby('id_return'):\n",
    "    if random.random() < 0.5:\n",
    "        order_items_df.loc[group_df.index, 'status'] = 'Returned'\n",
    "    else:\n",
    "        chosen_idx = random.choice(group_df.index.tolist())\n",
    "        order_items_df.loc[chosen_idx, 'status'] = 'Returned'\n",
    "\n",
    "# Cancelled 상태 지정\n",
    "order_items_df.loc[order_items_df['event_type_cancel'].notna(), 'status'] = 'Cancelled'\n",
    "\n",
    "\n",
    "# Step 3. 주문 생성 기준 정보 설정\n",
    "\n",
    "# 주문 생성 기준 이벤트 ID 설정\n",
    "mask_return = order_items_df['status'] == 'Returned'\n",
    "mask_cancel = order_items_df['status'] == 'Cancelled'\n",
    "\n",
    "order_items_df['created_from_event_id'] = order_items_df['id_purchase']\n",
    "order_items_df.loc[mask_return, 'created_from_event_id'] = order_items_df.loc[mask_return, 'id_return']\n",
    "order_items_df.loc[mask_cancel, 'created_from_event_id'] = order_items_df.loc[mask_cancel, 'id_cancel']\n",
    "\n",
    "# 주문 생성 시점(created_at) 설정\n",
    "order_items_df['created_at'] = order_items_df['created_at_purchase']\n",
    "order_items_df.loc[mask_return, 'created_at'] = order_items_df.loc[mask_return, 'created_at_return']\n",
    "order_items_df.loc[mask_cancel, 'created_at'] = order_items_df.loc[mask_cancel, 'created_at_cancel']\n",
    "\n",
    "\n",
    "# Step 4. 배송 및 반품 시간 생성\n",
    "\n",
    "# created_from_event_id 단위로 그룹화하여 처리\n",
    "for order, group_df in order_items_df.groupby('created_from_event_id'):\n",
    "\n",
    "    # Step 4 내부, Returned 상태 처리 영역에서 이 부분을 교체\n",
    "    # returned_idx = group_df[group_df['status'] == 'Returned'].index\n",
    "    \n",
    "    returned_idx = group_df[group_df['status'] == 'Returned'].index\n",
    "    \n",
    "    # shipped_at 초기값 설정 (모든 Returned 에 대해 일단 고정값 6시간)\n",
    "    order_items_df.loc[returned_idx, 'shipped_at'] = order_items_df.loc[returned_idx, 'created_at_purchase'] + pd.Timedelta(hours=6)\n",
    "    \n",
    "    # 조건 분기: 반품 생성 시점이 배송 전일 경우 → 배송 시점은 고정 (6시간 후), 이후 배송/반품 시간 생성\n",
    "    early_return_mask = order_items_df.loc[returned_idx, 'created_at_return'] < order_items_df.loc[returned_idx, 'shipped_at']\n",
    "    early_idx = returned_idx[early_return_mask]\n",
    "    \n",
    "    # → 고정 배송, 고정 이후 시간 설정\n",
    "    order_items_df.loc[early_idx, 'delivered_at'] = order_items_df.loc[early_idx, 'shipped_at'] + pd.to_timedelta(np.random.uniform(24, 72, len(early_idx)), unit='h')\n",
    "    order_items_df.loc[early_idx, 'returned_at'] = order_items_df.loc[early_idx, 'delivered_at'] + pd.to_timedelta(np.random.uniform(24, 72, len(early_idx)), unit='h')\n",
    "    \n",
    "    # 반대의 경우 (정상 흐름) → 기존 로직 유지\n",
    "    late_idx = returned_idx[~early_return_mask]\n",
    "    \n",
    "    order_items_df.loc[late_idx, 'shipped_at'] = order_items_df.loc[late_idx, 'created_at_purchase'] + pd.to_timedelta(np.random.uniform(6, 24, len(late_idx)), unit='h')\n",
    "    order_items_df.loc[late_idx, 'delivered_at'] = order_items_df.loc[late_idx, 'shipped_at'] + pd.to_timedelta(np.random.uniform(24, 72, len(late_idx)), unit='h')\n",
    "    order_items_df.loc[late_idx, 'returned_at'] = order_items_df.loc[late_idx, 'created_at_return'] + pd.to_timedelta(np.random.uniform(24, 72, len(late_idx)), unit='h')\n",
    "    \n",
    "    # 보정: created_at_return ≤ delivered_at 인 경우 returned_at 재설정\n",
    "    mask = (order_items_df.loc[late_idx, 'created_at_return'] <= order_items_df.loc[late_idx, 'delivered_at'])\n",
    "    idx_mask = late_idx[mask]\n",
    "    order_items_df.loc[idx_mask, 'returned_at'] = order_items_df.loc[idx_mask, 'delivered_at'] + pd.to_timedelta(np.random.uniform(24, 72, len(idx_mask)), unit='h')\n",
    "    \n",
    "    # end_date 초과 보정\n",
    "    order_items_df.loc[returned_idx[order_items_df.loc[returned_idx, 'returned_at'] >= end_date], 'returned_at'] = pd.NaT\n",
    "    order_items_df.loc[returned_idx[order_items_df.loc[returned_idx, 'delivered_at'] >= end_date], 'delivered_at'] = pd.NaT\n",
    "\n",
    "    # 기타 상태 (None) 배송 시간 생성 및 상태 결정\n",
    "    default_idx = group_df[group_df['status'].isna()].index\n",
    "\n",
    "    order_items_df.loc[default_idx, 'shipped_at'] = order_items_df.loc[default_idx, 'created_at_purchase'] + pd.to_timedelta(np.random.uniform(6, 24, len(default_idx)), unit='h')\n",
    "    order_items_df.loc[default_idx, 'delivered_at'] = order_items_df.loc[default_idx, 'shipped_at'] + pd.to_timedelta(np.random.uniform(24, 72, len(default_idx)), unit='h')\n",
    "\n",
    "    # 배송 시점에 따라 상태 결정\n",
    "    mask_processing = default_idx[order_items_df.loc[default_idx, 'shipped_at'] >= end_date]\n",
    "    order_items_df.loc[mask_processing, ['status', 'shipped_at', 'delivered_at']] = ['Packing', pd.NaT, pd.NaT]\n",
    "\n",
    "    mask_shipped = default_idx[(order_items_df.loc[default_idx, 'shipped_at'] < end_date) &\n",
    "                               (order_items_df.loc[default_idx, 'delivered_at'] >= end_date)]\n",
    "    order_items_df.loc[mask_shipped, ['status', 'delivered_at']] = ['Shipped', pd.NaT]\n",
    "\n",
    "    mask_purchased = default_idx[order_items_df.loc[default_idx, 'delivered_at'] < end_date]\n",
    "    order_items_df.loc[mask_purchased, 'status'] = 'Purchased'\n",
    "\n",
    "\n",
    "# Step 5. 주문 항목 ID 및 주문 ID 생성\n",
    "\n",
    "# 주문 항목 ID 생성 (고정 prefix + UUID 해시)\n",
    "namespace = uuid.NAMESPACE_DNS\n",
    "order_items_df['id'] = [str(uuid.uuid4())[:12] for _ in range(len(order_items_df))]\n",
    "order_items_df['id'] = ['oi-' + str(uuid.uuid5(namespace, str(idx)))[:12] for idx in range(len(order_items_df))]\n",
    "\n",
    "# id_purchase 컬럼을 활용해 order_id 생성\n",
    "namespace = uuid.NAMESPACE_DNS\n",
    "order_items_df['order_id'] = [f\"or-{str(uuid.uuid5(namespace, str(event_id)))[-12:]}\" for event_id in order_items_df['id_purchase']]\n",
    "\n",
    "# order_items_df 컬럼 순서 정리\n",
    "columns = ['id', 'order_id', 'created_from_event_id', 'user_id', 'product_id', 'general', 'timesale', 'created_at', 'status', 'shipped_at', 'delivered_at', 'returned_at']\n",
    "order_items_df = order_items_df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "\n",
    "\n",
    "# promotion_id 컬럼 생성 및 설정 \n",
    "\n",
    "# 데이터 로드 \n",
    "users_df = pd.read_csv(\"./data/users.csv\", usecols=['id', 'birth', 'gender'],parse_dates=['birth'])\n",
    "promotions_df = pd.read_csv(\"./data/promotions.csv\", parse_dates=['start_date', 'end_date'])\n",
    "\n",
    "# 컬럼 표준화 \n",
    "promotions_df = promotions_df.rename(columns={'id': 'promo_id'})\n",
    "users_df = users_df.rename(columns={'id': 'user_id'})\n",
    "\n",
    "# users 생일 월 컬럼 추가\n",
    "users_df['birth_month'] = users_df['birth'].dt.month\n",
    "\n",
    "# order_items 주문연도, 주문월 컬럼 추가 \n",
    "order_items_df['order_year'] = order_items_df['created_at'].dt.year\n",
    "order_items_df['order_month'] = order_items_df['created_at'].dt.month\n",
    "\n",
    "# order_items 테이블에 유저 생일 월 추가 (left Join)\n",
    "order_items_df = pd.merge(order_items_df, users_df, on='user_id', how='left')\n",
    "\n",
    "# 1) 정기 이벤트 프로모션 기간 매칭\n",
    "\n",
    "# 주문 시점이 정기 프로모션 기간에 해당하면 event_promo_id 부여 \n",
    "\n",
    "# promotions_df에서 정기(설/추석, 여름/가을 블랙 프라이데이) 프로모션 id 추출\n",
    "regular_promos = promotions_df.loc[promotions_df['promotion_type'] == '정기'].copy()\n",
    "\n",
    "# 정렬 \n",
    "regular_promos = regular_promos.sort_values('start_date')\n",
    "\n",
    "# order_items_df 정렬(created_at 기준)\n",
    "order_items_df = order_items_df.sort_values('created_at')\n",
    "\n",
    "\n",
    "# start_date 기준 주문 시점이 정기 프로모션 기간에 해당하면 promotion_id 부여\n",
    "order_items_df = pd.merge_asof(order_items_df, regular_promos[['promo_id', 'name', 'start_date', 'end_date']], \n",
    "                               left_on='created_at', right_on='start_date', direction='backward')\n",
    "\n",
    "# end_date 범위 내에 있는 주문만 promotion_id 유지\n",
    "range_in_end = (order_items_df['end_date'].notna()) & (order_items_df['created_at'] < order_items_df['end_date'] + timedelta(days=1))\n",
    "order_items_df['promotion_id'] = np.where(range_in_end, order_items_df['promo_id'], None)\n",
    "# 2) 생일 프로모션: 유저의 생일 달 첫 구매 (+타임세일 제외)\n",
    "\n",
    "# 타임세일 제외 \n",
    "general_purchase = order_items_df.loc[order_items_df['timesale'] == False]\n",
    "\n",
    "# 유저의 생일 달 == 구매달 \n",
    "is_birth_month = (general_purchase['order_month'] == general_purchase['birth_month'])\n",
    "\n",
    "# 유저별+연도별 생일 달 첫 주문 ID 구하기\n",
    "birth_first_order_ids = (\n",
    "    general_purchase[is_birth_month]\n",
    "    .sort_values([\"user_id\", \"order_year\", \"created_at\"])\n",
    "    .groupby([\"user_id\", \"order_year\"]) ['order_id']\n",
    "    .first()\n",
    ")\n",
    "\n",
    "# 그 주문 ID에 해당하는 모든 행들의 인덱스 뽑기\n",
    "birth_first_order_index = order_items_df.loc[order_items_df['order_id'].isin(birth_first_order_ids)].index\n",
    "\n",
    "order_items_df.loc[birth_first_order_index, 'promotion_id'] = promotions_df.loc[promotions_df['name'] == '생일자 프로모션', 'promo_id'].values[0]\n",
    "order_items_df.loc[birth_first_order_index, 'name'] = '생일자 프로모션'\n",
    "\n",
    "\n",
    "# 3) 타임 세일 프로모션 \n",
    "order_items_df.loc[order_items_df['timesale'] == True, 'promotion_id'] = promotions_df.loc[promotions_df['name'] == '타임세일', 'promo_id'].values[0]\n",
    "order_items_df.loc[order_items_df['timesale'] == True, 'name'] = '타임세일'\n",
    "\n",
    "columns = ['id', 'order_id', 'user_id', 'product_id', 'general', 'timesale', 'created_at', 'status', 'shipped_at', 'delivered_at', 'returned_at', 'promotion_id',  'created_from_event_id']\n",
    "order_items_df = order_items_df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_of_items 설정 함수 생성\n",
    "\n",
    "# ---------------------------\n",
    "# 1. 카테고리 그룹 매핑\n",
    "#    - 세부 sub_category를 몇 가지 대표 그룹으로 묶음\n",
    "#    - 그룹별로 구매 수량 분포를 정의하여 관리 용이성 확보\n",
    "# ---------------------------\n",
    "CATEGORY_GROUPS = {\n",
    "    \"outer\": [\n",
    "        '블루종', '레더 재킷', '코트', '패딩', '카디건', '기타 아우터'\n",
    "    ],\n",
    "    \"shoes_bags\": [\n",
    "        '스니커즈', '운동화', '부츠', '로퍼', '샌들', '슬리퍼', '구두',\n",
    "        '백팩', '크로스백', '숄더백', '기타 가방'\n",
    "    ],\n",
    "    \"tops_bottoms\": [\n",
    "        '반소매 티셔츠', '긴소매 티셔츠', '맨투맨', '후드 티셔츠',\n",
    "        '셔츠/블라우스', '니트', '데님 팬츠', '슬랙스', '조거 팬츠',\n",
    "        '숏 팬츠', '기타 바지'\n",
    "    ],\n",
    "    \"onepiece_skirt\": [\n",
    "        '미니 원피스', '셔츠 원피스', '미디 원피스', '니트 원피스', '맥시 원피스',\n",
    "        '미니 스커트', '롱 스커트', '미디 스커트'\n",
    "    ],\n",
    "    \"underwear\": [\n",
    "        '브라', '팬티', '이너웨어', '세트 속옷', '속바지'\n",
    "    ],\n",
    "    \"accessory\": [\n",
    "        '모자', '벨트', '시계', '양말', '장갑', '안경/선글라스', '기타 악세사리'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ---------------------------\n",
    "# 2. 분포 정의 (DISTRIBUTIONS)\n",
    "#    - 각 그룹/세부 속성별로 구매 수량 분포 정의\n",
    "#    - 예: 팬티는 여러 장 구매하는 경향 반영, 아우터는 대부분 1개\n",
    "# ---------------------------\n",
    "DISTRIBUTIONS = {\n",
    "    \"outer\":        {1: 0.97, 2: 0.03},                                # 아우터: 사실상 1개\n",
    "    \"shoes_bags\":   {1: 0.95, 2: 0.05},                                # 신발/가방도 거의 1개\n",
    "    \"tops_bottoms\": {1: 0.82, 2: 0.15, 3: 0.03},                       # 기본 의류: 2~3개 가능\n",
    "    \"onepiece_skirt\": {1: 0.94, 2: 0.06},                              # 원피스/스커트: 1개 중심\n",
    "    \"underwear_bra\":   {1: 0.88, 2: 0.12},                             # 브라: 보통 1~2개\n",
    "    \"underwear_panty\": {1: 0.40, 2: 0.35, 3: 0.15, 4: 0.07, 5: 0.03},  # 팬티: 3~5개까지 현실적\n",
    "    \"underwear_other\": {1: 0.65, 2: 0.25, 3: 0.07, 4: 0.03},           # 속바지/이너웨어: 2~3개 가능\n",
    "    \"accessory\":    {1: 0.96, 2: 0.03, 3: 0.01}                        # 액세서리: 묶음 가능성 소량 반영\n",
    "}\n",
    "\n",
    "# ---------------------------\n",
    "# 3. sub_category → 그룹명 매핑 딕셔너리\n",
    "#    - 빠른 검색을 위해 모든 sub_category를 그룹명으로 매핑\n",
    "# ---------------------------\n",
    "subcat_to_group = {}\n",
    "for group, subs in CATEGORY_GROUPS.items():\n",
    "    for s in subs:\n",
    "        subcat_to_group[s] = group\n",
    "\n",
    "# ---------------------------\n",
    "# 4. 프로모션 승수 정의\n",
    "#    - 프로모션 타입별로 \"2개 이상\" 구매 확률을 증가시킴\n",
    "#    - 일반: 그대로, 정기전: 1.25배, 타임세일: 1.40배\n",
    "# ---------------------------\n",
    "PROMO_MULTIPLIER = {\n",
    "    \"일반\": 1.00,\n",
    "    \"정기\": 1.25,   # 정기전\n",
    "    \"상시\": 1.40,   # 타임세일\n",
    "}\n",
    "\n",
    "def apply_promo_boost(dist: dict, promo_type: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    주어진 구매 수량 분포(dist)에 프로모션 승수를 적용\n",
    "    - 프로모션이 있는 경우, 수량 ≥ 2인 항목의 확률을 승수만큼 증가\n",
    "    - 확률 전체를 다시 정규화\n",
    "    \n",
    "    input:\n",
    "        dist (dict): {수량: 확률}\n",
    "        promo_type (str): 프로모션 타입 ('일반','정기','상시')\n",
    "    \n",
    "    return:\n",
    "        qty (np.ndarray): 가능한 수량\n",
    "        prob (np.ndarray): 해당 수량의 확률 벡터\n",
    "    \"\"\"\n",
    "    items = sorted(dist.items())  # (qty, prob)\n",
    "    qty = np.array([k for k,_ in items], dtype=int)\n",
    "    prob = np.array([v for _,v in items], dtype=float)\n",
    "\n",
    "    mult = PROMO_MULTIPLIER.get(str(promo_type).lower(), 1.0)\n",
    "    if mult != 1.0:\n",
    "        prob[qty >= 2] *= mult\n",
    "        prob /= prob.sum()\n",
    "    \n",
    "    return qty, prob\n",
    "\n",
    "# ---------------------------\n",
    "# 5. 샘플링 함수\n",
    "# ---------------------------\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "def get_base_dist(sub_category: str):\n",
    "    \"\"\"\n",
    "    주어진 sub_category에 대해 기본 구매 수량 분포(dict)를 반환합니다.\n",
    "    \n",
    "    - 언더웨어(브라/팬티/기타)는 세부적으로 분리하여 각기 다른 분포를 사용\n",
    "    - 그 외의 경우, sub_category → 그룹명 매핑(subcat_to_group)에 따라 그룹 단위 분포를 사용\n",
    "    - 매핑이 없으면 기본값으로 'accessory' 그룹 분포를 사용\n",
    "    \n",
    "    input:\n",
    "        sub_category : 상품의 세부 카테고리 (예: '팬티', '코트', '반소매 티셔츠' 등)(str)\n",
    "        \n",
    "    \n",
    "    return:\n",
    "        dict: 구매 수량 분포 {수량: 확률} (예: {1: 0.85, 2: 0.15} → 1개 구매 확률 85%, 2개 구매 확률 15%)\n",
    "    \"\"\"\n",
    "    group = subcat_to_group.get(sub_category, \"accessory\")\n",
    "    if group == \"underwear\":\n",
    "        if sub_category == \"브라\":\n",
    "            return DISTRIBUTIONS[\"underwear_bra\"]\n",
    "        elif sub_category == \"팬티\":\n",
    "            return DISTRIBUTIONS[\"underwear_panty\"]\n",
    "        else:\n",
    "            return DISTRIBUTIONS[\"underwear_other\"]\n",
    "    return DISTRIBUTIONS.get(group, DISTRIBUTIONS[\"accessory\"])\n",
    "\n",
    "def sample_num_of_items_vectorized(sub_categories: pd.Series, promo_types: pd.Series) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    대규모 데이터셋에 대해 벡터화 방식으로 num_of_items 생성\n",
    "    \n",
    "    input:\n",
    "        sub_categories: 상품 sub_category (Series)\n",
    "        promo_types   : 프로모션 타입 (Series) → '일반','정기','상시'\n",
    "    \n",
    "    return:\n",
    "        np.ndarray: 각 row별 샘플링된 구매 수량\n",
    "    \"\"\"\n",
    "    out = np.empty(len(sub_categories), dtype=int)\n",
    "\n",
    "    # 조합별로 한번만 분포 계산 → 해당 인덱스에 일괄 샘플\n",
    "    keys = pd.DataFrame({\"sub_category\": sub_categories.values,\n",
    "                         \"promotion_type\": promo_types.fillna(\"일반\").values})\n",
    "    \n",
    "    for (sc, pt), idx in keys.groupby([\"sub_category\",\"promotion_type\"]).groups.items():\n",
    "        base = get_base_dist(sc)\n",
    "        qty, prob = apply_promo_boost(base, pt)\n",
    "        n = len(idx)\n",
    "        u = rng.random(n)\n",
    "        cum = prob.cumsum()\n",
    "        out[idx] = qty[np.searchsorted(cum, u)] # 누적 확률 분포에서 랜덤 샘플링\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5\n",
    "# 정기 프로모션 기간 중 정기 프로모션 최종 판별 및 num_of_items 생성\n",
    "\n",
    "# 데이터 로드 \n",
    "products_df = pd.read_csv(\"./data/products.csv\", usecols=['id', 'sub_category', 'retail_price'])\n",
    "products_df = products_df.rename(columns={'id': 'product_id'})\n",
    "\n",
    "# order_items_df + product_df (left join) \n",
    "order_items_df = pd.merge(order_items_df, products_df, left_on='product_id', right_on='product_id', how='left')\n",
    "\n",
    "# ----------------\n",
    "# num_of_items 컬럼 생성\n",
    "order_items_df = pd.merge(order_items_df, promotions_df, left_on='promotion_id', right_on='promo_id', how='left')\n",
    "order_items_df = order_items_df.drop(columns=['promo_id'])\n",
    "\n",
    "order_items_df[\"num_of_items\"] = sample_num_of_items_vectorized(\n",
    "    order_items_df[\"sub_category\"],\n",
    "    order_items_df[\"promotion_type\"]\n",
    ")\n",
    "# ----------------\n",
    "\n",
    "# 정기 프로모션 행 추출 \n",
    "regular_promo_df = order_items_df.loc[order_items_df['promotion_type'] == '정기'].copy()\n",
    "\n",
    "regular_promo_df['total_price'] = regular_promo_df['retail_price'] * regular_promo_df['num_of_items']\n",
    "\n",
    "regular_promo_sum_df = regular_promo_df.groupby(['promotion_id','order_id'], as_index=False)['total_price'].sum()\n",
    "\n",
    "regular_promo_sum_df = pd.merge(regular_promo_sum_df, promotions_df, left_on='promotion_id', right_on='promo_id', how='left')\n",
    "\n",
    "higher_mask = regular_promo_sum_df['total_price'] >= regular_promo_sum_df['minimum_sale_price']\n",
    "\n",
    "higher_order_ids = regular_promo_sum_df.loc[higher_mask, 'order_id'].unique().tolist()\n",
    "lower_order_ids  = regular_promo_sum_df.loc[~higher_mask, 'order_id'].unique().tolist()\n",
    "\n",
    "# 프로모션 기간 중 구매자가 프로모션에 대한 무지로 인한 프로모션 미적용\n",
    "# λ 설정 (예: 평균 2% 정도 프로모션 놓침)\n",
    "num_miss = np.random.poisson(0.02 * len(higher_order_ids))  # 전체 개수 대비 비율 반영\n",
    "num_miss = random.sample(higher_order_ids, num_miss)in(num_miss, len(higher_order_ids))  # 안전장치: 리스트보다 많지 않게\n",
    "missed_ids = random.sample(higher_order_ids, num_miss)\n",
    "\n",
    "order_items_df.loc[(order_items_df['order_id'].isin(missed_ids)) & (order_items_df['promotion_type'] == '정기'), 'promotion_id'] = None\n",
    "order_items_df.loc[(order_items_df['order_id'].isin(lower_order_ids)) & (order_items_df['promotion_type'] == '정기'), 'promotion_id'] = None\n",
    "\n",
    "# 컬럼 정리 및 order_items_df로 저장 (prmotion_id가 새로 조정되었기 때문에 다시 promotions랑 조인해야함.)\n",
    "columns = ['id', 'order_id', 'user_id', 'product_id', 'sub_category', 'promotion_id', 'status', 'created_at', 'shipped_at', 'delivered_at', 'returned_at', 'retail_price', 'num_of_items', 'created_from_event_id']\n",
    "order_items_df = order_items_df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>promotion_id</th>\n",
       "      <th>status</th>\n",
       "      <th>created_at</th>\n",
       "      <th>shipped_at</th>\n",
       "      <th>delivered_at</th>\n",
       "      <th>returned_at</th>\n",
       "      <th>retail_price</th>\n",
       "      <th>num_of_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oi-243f3f83-b1c</td>\n",
       "      <td>or-7949a6c1242d</td>\n",
       "      <td>44091</td>\n",
       "      <td>6277ead6</td>\n",
       "      <td>슬리퍼</td>\n",
       "      <td>1</td>\n",
       "      <td>Purchased</td>\n",
       "      <td>2022-01-01 00:01:24</td>\n",
       "      <td>2022-01-01 21:44:32.738778</td>\n",
       "      <td>2022-01-03 00:21:22.563303</td>\n",
       "      <td>NaT</td>\n",
       "      <td>34600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oi-6850d5b8-3f7</td>\n",
       "      <td>or-d25190faeced</td>\n",
       "      <td>54098</td>\n",
       "      <td>9a48e33a</td>\n",
       "      <td>기타 가방</td>\n",
       "      <td>14</td>\n",
       "      <td>Purchased</td>\n",
       "      <td>2022-01-01 00:02:07</td>\n",
       "      <td>2022-01-01 21:45:15.738778</td>\n",
       "      <td>2022-01-03 00:22:05.563303</td>\n",
       "      <td>NaT</td>\n",
       "      <td>43100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oi-3cf5e834-10f</td>\n",
       "      <td>or-1dbf72891640</td>\n",
       "      <td>80078</td>\n",
       "      <td>62f1995c</td>\n",
       "      <td>니트</td>\n",
       "      <td>1</td>\n",
       "      <td>Purchased</td>\n",
       "      <td>2022-01-01 00:02:17</td>\n",
       "      <td>2022-01-01 21:45:25.738778</td>\n",
       "      <td>2022-01-03 00:22:15.563303</td>\n",
       "      <td>NaT</td>\n",
       "      <td>87100</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oi-58404489-33a</td>\n",
       "      <td>or-69bb2c4b6472</td>\n",
       "      <td>4993</td>\n",
       "      <td>d4c7b0df</td>\n",
       "      <td>이너웨어</td>\n",
       "      <td>1</td>\n",
       "      <td>Purchased</td>\n",
       "      <td>2022-01-01 00:02:18</td>\n",
       "      <td>2022-01-01 21:45:26.738778</td>\n",
       "      <td>2022-01-03 00:22:16.563303</td>\n",
       "      <td>NaT</td>\n",
       "      <td>20800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oi-41e9a902-06e</td>\n",
       "      <td>or-bbc191a03533</td>\n",
       "      <td>93217</td>\n",
       "      <td>665b3f4b</td>\n",
       "      <td>긴소매 티셔츠</td>\n",
       "      <td>1</td>\n",
       "      <td>Purchased</td>\n",
       "      <td>2022-01-01 00:02:32</td>\n",
       "      <td>2022-01-01 21:45:40.738778</td>\n",
       "      <td>2022-01-03 00:22:30.563303</td>\n",
       "      <td>NaT</td>\n",
       "      <td>40400</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id         order_id  user_id product_id sub_category  \\\n",
       "0  oi-243f3f83-b1c  or-7949a6c1242d    44091   6277ead6          슬리퍼   \n",
       "1  oi-6850d5b8-3f7  or-d25190faeced    54098   9a48e33a        기타 가방   \n",
       "2  oi-3cf5e834-10f  or-1dbf72891640    80078   62f1995c           니트   \n",
       "3  oi-58404489-33a  or-69bb2c4b6472     4993   d4c7b0df         이너웨어   \n",
       "4  oi-41e9a902-06e  or-bbc191a03533    93217   665b3f4b      긴소매 티셔츠   \n",
       "\n",
       "  promotion_id     status          created_at                 shipped_at  \\\n",
       "0            1  Purchased 2022-01-01 00:01:24 2022-01-01 21:44:32.738778   \n",
       "1           14  Purchased 2022-01-01 00:02:07 2022-01-01 21:45:15.738778   \n",
       "2            1  Purchased 2022-01-01 00:02:17 2022-01-01 21:45:25.738778   \n",
       "3            1  Purchased 2022-01-01 00:02:18 2022-01-01 21:45:26.738778   \n",
       "4            1  Purchased 2022-01-01 00:02:32 2022-01-01 21:45:40.738778   \n",
       "\n",
       "                delivered_at returned_at  retail_price  num_of_items  \n",
       "0 2022-01-03 00:21:22.563303         NaT         34600             1  \n",
       "1 2022-01-03 00:22:05.563303         NaT         43100             1  \n",
       "2 2022-01-03 00:22:15.563303         NaT         87100             2  \n",
       "3 2022-01-03 00:22:16.563303         NaT         20800             1  \n",
       "4 2022-01-03 00:22:30.563303         NaT         40400             2  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_items_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6\n",
    "# retail_price, sale_price 컬럼 생성 및 설정 \n",
    "\n",
    "# order_items_df + promotions_df left join (prmotion_id가 새로 조정되었기 때문에 다시 promotions랑 조인해야함.)\n",
    "order_items_df = pd.merge(order_items_df, promotions_df, left_on='promotion_id', right_on='promo_id', how='left')\n",
    "\n",
    "# 1) sale_price(각 주문행의 최종 가격)\n",
    "order_items_df['sale_price'] = order_items_df['num_of_items'] * order_items_df['retail_price']\n",
    "\n",
    "# 2) 타임세일 sale_price 설정\n",
    "timesale_df = order_items_df.loc[order_items_df['name'] == '타임세일'].copy()\n",
    "# sale_price 계산\n",
    "timesale_df['sale_price'] = timesale_df['retail_price'] * timesale_df['num_of_items'] * (1 - timesale_df['discount_rate'])\n",
    "order_items_df.loc[timesale_df.index, 'sale_price'] = timesale_df['sale_price']\n",
    "\n",
    "# 3) 생일자, 설/추석, 가을/여름 블랙프라이데이 sale_price 설정\n",
    "# 생일자, 설/추석, 가을/여름 블랙프라이데이 행 추출 \n",
    "birth_regular_df = order_items_df.loc[(order_items_df['promotion_type'] == '정기') | (order_items_df['name'] == '생일자 프로모션')].copy()\n",
    "\n",
    "# Total_price 컬럼 생성\n",
    "birth_regular_df['total_price'] = birth_regular_df['retail_price'] * birth_regular_df['num_of_items']\n",
    "\n",
    "# 할인 금액 컬럼 생성\n",
    "birth_regular_df['discount_price'] = birth_regular_df['total_price'] * birth_regular_df['discount_rate']\n",
    "\n",
    "# 정렬\n",
    "birth_regular_df = birth_regular_df.sort_values(by=['user_id', 'order_id', 'retail_price'], ascending=[True, True, False])\n",
    "\n",
    "# 누적 할인 금액 컬럼 생성\n",
    "birth_regular_df['cum_discount_price'] = birth_regular_df.groupby(['user_id', 'order_id'])['discount_price'].cumsum()\n",
    "\n",
    "birth_regular_df['prev_order_id'] = birth_regular_df.groupby('user_id')['order_id'].shift(1)\n",
    "\n",
    "# 누적 할인 금액이 최대 할인 금액 보다 높은 인덱스, 낮은 인덱스 추출 \n",
    "over_idx = birth_regular_df.loc[birth_regular_df['cum_discount_price'] > birth_regular_df['maximum_discount_price']].index.tolist()\n",
    "under_idx = birth_regular_df.loc[birth_regular_df['cum_discount_price'] <= birth_regular_df['maximum_discount_price']].index.tolist()\n",
    "# 인덱스에 맞는 sale_price 설정 \n",
    "if under_idx:\n",
    "    order_items_df.loc[under_idx, 'sale_price'] = birth_regular_df['total_price'] - birth_regular_df['discount_price']\n",
    "if over_idx:\n",
    "    for idx, row in birth_regular_df.loc[over_idx].iterrows():\n",
    "        if row['prev_order_id'].isna():\n",
    "            order_items_df.at[idx, 'sale_price'] = birth_regular_df['total_price'] - birth_regular_df['discount_price'] \n",
    "            + (birth_regular_df['cum_discount_price'] - birth_regular_df['maximum_discount_price'])\n",
    "        else:\n",
    "            order_items_df.at[idx, 'sale_price'] = birth_regular_df['total_price']\n",
    "\n",
    "# 최종 order_items_df 생성 \n",
    "columns = ['id', 'order_id', 'user_id', 'product_id', 'status', 'created_at','shipped_at', 'delivered_at', 'returned_at','promotion_id', 'name', 'discount_rate', 'retail_price', 'num_of_items', 'sale_price', 'created_from_event_id']\n",
    "order_items_df = order_items_df[columns]\n",
    "order_items_df = order_items_df.rename(columns={'name': 'promotion_name'})\n",
    "\n",
    "# promotion_id 컬럼 int형으로 변환 (+ None -> -1)\n",
    "order_items_df['promotion_id'] = order_items_df['promotion_id'].fillna(-1).astype('int64')\n",
    "\n",
    "# created_at, shipped_at, delivered_at, returned_at 시간 처리 \n",
    "order_items_df['created_at'] = order_items_df['created_at'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "order_items_df['created_at'] = pd.to_datetime(order_items_df['created_at'])\n",
    "\n",
    "order_items_df['shipped_at'] = order_items_df['shipped_at'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "order_items_df['shipped_at'] = pd.to_datetime(order_items_df['shipped_at'])\n",
    "\n",
    "order_items_df['delivered_at'] = order_items_df['delivered_at'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "order_items_df['delivered_at'] = pd.to_datetime(order_items_df['delivered_at'])\n",
    "\n",
    "order_items_df['returned_at'] = order_items_df['returned_at'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "order_items_df['returned_at'] = pd.to_datetime(order_items_df['returned_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order_items_df 저장\n",
    "order_items_df.to_csv(\"./data/order_items.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 연간 구매액 기준 회원 등급 부여 (users.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_user_tiers(users: pd.DataFrame, order_items: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    연간 구매액(Annual Spend)을 기준으로 사용자별 회원 등급(loyal, regular, dormant)을 부여합니다.\n",
    "\n",
    "    로직:\n",
    "        1) order_items 테이블에서 user_id 기준으로 연간 구매액(total_spend)을 집계\n",
    "        2) users 테이블과 병합하여 각 사용자의 연간 구매액을 계산\n",
    "        3) 구매액 구간을 기준으로 tier 컬럼을 생성\n",
    "           - loyal   : 상위 고객 (연간 구매액 >= 500,000원)\n",
    "           - regular : 일반 고객 (연간 구매액 100,000원 ~ 500,000원 미만)\n",
    "           - dormant : 저활성 고객 (연간 구매액 < 100,000원 또는 구매 이력 없음)\n",
    "\n",
    "    input:\n",
    "        users (pd.DataFrame): 사용자 정보 테이블. 최소한 'id' 컬럼 필요.\n",
    "        order_items (pd.DataFrame): 주문 상세 테이블. 최소한 'user_id', 'sale_price' 컬럼 필요.\n",
    "\n",
    "    return:\n",
    "        pd.DataFrame: tier 컬럼이 추가된 users DataFrame\n",
    "    \"\"\"\n",
    "    # 1) 연간 구매액 집계\n",
    "    annual_spend = (\n",
    "        order_items.groupby(\"user_id\")[\"sale_price\"]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"sale_price\": \"annual_spend\"})\n",
    "    )\n",
    "\n",
    "    # 2) users 테이블과 병합\n",
    "    users = users.merge(annual_spend, left_on=\"id\", right_on=\"user_id\", how=\"left\")\n",
    "    users[\"annual_spend\"] = users[\"annual_spend\"].fillna(0)\n",
    "\n",
    "    # 3) 구간 기준 tier 부여\n",
    "    def classify_tier(spend):\n",
    "        if spend >= 500_000:\n",
    "            return \"loyal\"\n",
    "        elif spend >= 100_000:\n",
    "            return \"regular\"\n",
    "        else:\n",
    "            return \"dormant\"\n",
    "\n",
    "    users[\"user_type\"] = users[\"annual_spend\"].apply(classify_tier)\n",
    "\n",
    "    return users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = pd.read_csv('./data/users.csv', parse_dates=['birth', 'created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = assign_user_tiers(users_df, order_items_df)\n",
    "column_order = ['id', 'created_at', 'user_type', 'first_name', 'last_name', 'email',\n",
    "                'age', 'birth', 'gender', 'address', 'traffic_source']\n",
    "users_df = users_df[column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df.to_csv('./data/users.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 \n",
    "order_items_df = pd.read_csv(\"./data/order_items.csv\", parse_dates=['created_at','shipped_at', 'delivered_at', 'returned_at'])\n",
    "users_df = pd.read_csv(\"./data/users.csv\", usecols=['id', 'gender'])\n",
    "users_df = users_df.rename(columns={'id': 'user_id'})\n",
    "\n",
    "# 주문 상태 정리 함수\n",
    "def map_order_status(group):\n",
    "    statuses = set(group)\n",
    "    if statuses == {'Purchased'}:\n",
    "        return 'Complete'\n",
    "    elif statuses == {'Returned'}:\n",
    "        return 'Complete'\n",
    "    elif statuses == {'Purchased', 'Returned'}:\n",
    "        return 'Completed'\n",
    "    elif 'Cancelled' in statuses:\n",
    "        return 'Cancelled'\n",
    "    else:\n",
    "        return 'Processing'\n",
    "\n",
    "\n",
    "        \n",
    "# orders 테이블 생성 + gender\n",
    "orders_df = (\n",
    "    order_items_df.groupby('order_id').agg(\n",
    "        user_id=('user_id', 'first'),\n",
    "        status=('status', map_order_status),\n",
    "        created_at=('created_at', 'max'),\n",
    "        shipped_at=('shipped_at', 'max'),\n",
    "        delivered_at=('delivered_at', 'max'),\n",
    "        returned_at=('returned_at', 'max'),\n",
    "        num_of_items=('num_of_items', 'sum')\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# gender컬럼 생성\n",
    "orders_df = pd.merge(orders_df, users_df, on='user_id', how='left')\n",
    "\n",
    "# 컬럼 정리\n",
    "columns = ['order_id', 'user_id', 'status', 'gender', 'created_at', 'shipped_at', 'delivered_at', 'returned_at', 'num_of_items']\n",
    "orders_df = orders_df.rename(columns={'order_id': 'id'})\n",
    "orders_df = orders_df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orders_df 저장\n",
    "orders_df.to_csv(\"./data/orders.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecommerce_pjt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
